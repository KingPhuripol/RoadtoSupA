{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":92678,"databundleVersionId":11040229,"sourceType":"competition"}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip -q install autogluon","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-04-06T13:33:40.208379Z","iopub.execute_input":"2025-04-06T13:33:40.208649Z","iopub.status.idle":"2025-04-06T13:34:24.715374Z","shell.execute_reply.started":"2025-04-06T13:33:40.208628Z","shell.execute_reply":"2025-04-06T13:34:24.714486Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.2/266.2 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/64.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m430.0/430.0 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.2/352.2 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.7/174.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.2/68.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.7/196.7 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.4/324.4 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m818.9/818.9 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.7/314.7 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m681.8/681.8 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from autogluon.tabular import TabularDataset, TabularPredictor","metadata":{"execution":{"iopub.status.busy":"2025-04-06T13:34:30.115161Z","iopub.execute_input":"2025-04-06T13:34:30.115454Z","iopub.status.idle":"2025-04-06T13:34:31.380800Z","shell.execute_reply.started":"2025-04-06T13:34:30.115427Z","shell.execute_reply":"2025-04-06T13:34:31.380202Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2025-04-06T13:34:33.493336Z","iopub.execute_input":"2025-04-06T13:34:33.493859Z","iopub.status.idle":"2025-04-06T13:34:33.497593Z","shell.execute_reply.started":"2025-04-06T13:34:33.493829Z","shell.execute_reply":"2025-04-06T13:34:33.496721Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# start","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/hearth-disease-recognition/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2025-04-06T13:34:37.827482Z","iopub.execute_input":"2025-04-06T13:34:37.827769Z","iopub.status.idle":"2025-04-06T13:34:38.755921Z","shell.execute_reply.started":"2025-04-06T13:34:37.827745Z","shell.execute_reply":"2025-04-06T13:34:38.755113Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_data['History of HeartDisease or Attack'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2025-04-06T13:34:40.714524Z","iopub.execute_input":"2025-04-06T13:34:40.714827Z","iopub.status.idle":"2025-04-06T13:34:40.742235Z","shell.execute_reply.started":"2025-04-06T13:34:40.714806Z","shell.execute_reply":"2025-04-06T13:34:40.741362Z"},"trusted":true},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"History of HeartDisease or Attack\nNo     203322\nYes     18068\nName: count, dtype: int64"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"# preprocess","metadata":{}},{"cell_type":"code","source":"# delete target null\nprint(len(train_data))\ntrain_data = train_data.dropna(subset=['History of HeartDisease or Attack'])\nprint(len(train_data))","metadata":{"execution":{"iopub.status.busy":"2025-04-06T13:34:45.572399Z","iopub.execute_input":"2025-04-06T13:34:45.572727Z","iopub.status.idle":"2025-04-06T13:34:45.646830Z","shell.execute_reply.started":"2025-04-06T13:34:45.572699Z","shell.execute_reply":"2025-04-06T13:34:45.646134Z"},"trusted":true},"outputs":[{"name":"stdout","text":"223084\n221390\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"train_data[\"Age\"].describe()","metadata":{"execution":{"iopub.status.busy":"2025-04-06T13:34:46.000502Z","iopub.execute_input":"2025-04-06T13:34:46.000734Z","iopub.status.idle":"2025-04-06T13:34:46.016362Z","shell.execute_reply.started":"2025-04-06T13:34:46.000715Z","shell.execute_reply":"2025-04-06T13:34:46.015691Z"},"trusted":true},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"count    221390.000000\nmean         54.660215\nstd          17.773171\nmin          18.000000\n25%          42.000000\n50%          56.000000\n75%          67.000000\nmax         100.000000\nName: Age, dtype: float64"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\ndef create_new_features(train_data):\n    # \"\"\"\n    # This function creates 10 new features from the existing columns in train_data.\n    # It assumes that many binary columns are coded as \"Yes\"/\"No\" and converts them into 1/0.\n    # It also maps categorical education and income levels into numeric scores.\n    # \"\"\"\n    # --- Helper: Convert Yes/No to binary ---\n    binary_map = {\"Yes\": 1, \"No\": 0}\n    binary_cols = [\n        \"High Blood Pressure\", \"Told High Cholesterol\", \"Cholesterol Checked\",\n        \"Smoked 100+ Cigarettes\", \"Diagnosed Stroke\", \"Diagnosed Diabetes\",\n        \"Leisure Physical Activity\", \"Heavy Alcohol Consumption\",\n        \"Health Care Coverage\", \"Doctor Visit Cost Barrier\",\n        \"Difficulty Walking\", \"Vegetable or Fruit Intake (1+ per Day)\"\n    ]\n    \n    for col in binary_cols:\n        # Create a new binary column with suffix '_bin'\n        if train_data[col].dtype == object:\n            train_data[col + \"_bin\"] = train_data[col].map(binary_map)\n        else:\n            train_data[col + \"_bin\"] = train_data[col]\n\n\n    # --------Feature 2 ------------\n    def categorize_bmi(bmi): # GOOD \n        if bmi < 18.5:\n            return \"Underweight\"\n        elif bmi < 25:\n            return \"Normal weight\"\n        elif bmi < 30:\n            return \"Overweight\"\n        else:\n            return \"Obese\"\n\n    train_data['BMI Category'] = train_data['Body Mass Index'].apply(categorize_bmi)\n\n    # # Derived Feature: Obesity Risk # may be good, GOOD\n    train_data['Obesity Risk'] = ((train_data['Body Mass Index'] >= 30) & (train_data['Leisure Physical Activity'] == 'No')).astype(int)\n\n    # #Drop column\n    columns_to_drop = [\n        \"High Blood Pressure_bin\", \"Told High Cholesterol_bin\", \"Cholesterol Checked_bin\",\n        \"Smoked 100+ Cigarettes_bin\", \"Diagnosed Stroke_bin\", \"Diagnosed Diabetes_bin\",\n        \"Leisure Physical Activity_bin\", \"Heavy Alcohol Consumption_bin\",\n        \"Health Care Coverage_bin\", \"Doctor Visit Cost Barrier_bin\",\n        \"Difficulty Walking_bin\", \"Vegetable or Fruit Intake (1+ per Day)_bin\",\n        \"Leisure Physical Activity\",\n    ]\n    train_data = train_data.drop(columns=columns_to_drop)\n\n    \n\n\n    return train_data\n\n","metadata":{"execution":{"iopub.status.busy":"2025-04-06T13:34:46.994284Z","iopub.execute_input":"2025-04-06T13:34:46.994522Z","iopub.status.idle":"2025-04-06T13:34:47.001122Z","shell.execute_reply.started":"2025-04-06T13:34:46.994502Z","shell.execute_reply":"2025-04-06T13:34:47.000207Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"train_data = create_new_features(train_data)\ntrain_data.head(3)","metadata":{"execution":{"iopub.status.busy":"2025-04-06T13:34:51.684582Z","iopub.execute_input":"2025-04-06T13:34:51.684888Z","iopub.status.idle":"2025-04-06T13:34:51.952090Z","shell.execute_reply.started":"2025-04-06T13:34:51.684860Z","shell.execute_reply":"2025-04-06T13:34:51.951233Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"             ID History of HeartDisease or Attack High Blood Pressure  \\\n0  train_000001                                No                 Yes   \n1  train_000002                                No                  No   \n2  train_000003                                No                 Yes   \n\n  Told High Cholesterol Cholesterol Checked  Body Mass Index  \\\n0                   Yes                 Yes            40.68   \n1                    No                  No            24.36   \n2                   Yes                 Yes            27.33   \n\n  Smoked 100+ Cigarettes Diagnosed Stroke Diagnosed Diabetes  \\\n0                    Yes               No                 No   \n1                    Yes               No                 No   \n2                     No               No                 No   \n\n  Heavy Alcohol Consumption  ... Doctor Visit Cost Barrier General Health  \\\n0                        No  ...                        No      Very Poor   \n1                        No  ...                       Yes           Fair   \n2                        No  ...                       Yes      Very Poor   \n\n  Difficulty Walking     Sex       Education Level  \\\n0                Yes  Female  High school graduate   \n1                 No  Female      College graduate   \n2                Yes  Female  High school graduate   \n\n                   Income Level Age  Vegetable or Fruit Intake (1+ per Day)  \\\n0  $15,000 to less than $20,000  64                                     Yes   \n1             Less than $10,000  50                                      No   \n2               $75,000 or more  61                                     Yes   \n\n    BMI Category Obesity Risk  \n0          Obese            1  \n1  Normal weight            0  \n2     Overweight            0  \n\n[3 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>History of HeartDisease or Attack</th>\n      <th>High Blood Pressure</th>\n      <th>Told High Cholesterol</th>\n      <th>Cholesterol Checked</th>\n      <th>Body Mass Index</th>\n      <th>Smoked 100+ Cigarettes</th>\n      <th>Diagnosed Stroke</th>\n      <th>Diagnosed Diabetes</th>\n      <th>Heavy Alcohol Consumption</th>\n      <th>...</th>\n      <th>Doctor Visit Cost Barrier</th>\n      <th>General Health</th>\n      <th>Difficulty Walking</th>\n      <th>Sex</th>\n      <th>Education Level</th>\n      <th>Income Level</th>\n      <th>Age</th>\n      <th>Vegetable or Fruit Intake (1+ per Day)</th>\n      <th>BMI Category</th>\n      <th>Obesity Risk</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_000001</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>40.68</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>...</td>\n      <td>No</td>\n      <td>Very Poor</td>\n      <td>Yes</td>\n      <td>Female</td>\n      <td>High school graduate</td>\n      <td>$15,000 to less than $20,000</td>\n      <td>64</td>\n      <td>Yes</td>\n      <td>Obese</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_000002</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>24.36</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>Fair</td>\n      <td>No</td>\n      <td>Female</td>\n      <td>College graduate</td>\n      <td>Less than $10,000</td>\n      <td>50</td>\n      <td>No</td>\n      <td>Normal weight</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_000003</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>27.33</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>Very Poor</td>\n      <td>Yes</td>\n      <td>Female</td>\n      <td>High school graduate</td>\n      <td>$75,000 or more</td>\n      <td>61</td>\n      <td>Yes</td>\n      <td>Overweight</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 21 columns</p>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"train_data.iloc[0]","metadata":{"execution":{"iopub.status.busy":"2025-04-06T13:34:54.960577Z","iopub.execute_input":"2025-04-06T13:34:54.960856Z","iopub.status.idle":"2025-04-06T13:34:54.967242Z","shell.execute_reply.started":"2025-04-06T13:34:54.960833Z","shell.execute_reply":"2025-04-06T13:34:54.966407Z"},"trusted":true},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"ID                                                        train_000001\nHistory of HeartDisease or Attack                                   No\nHigh Blood Pressure                                                Yes\nTold High Cholesterol                                              Yes\nCholesterol Checked                                                Yes\nBody Mass Index                                                  40.68\nSmoked 100+ Cigarettes                                             Yes\nDiagnosed Stroke                                                    No\nDiagnosed Diabetes                                                  No\nHeavy Alcohol Consumption                                           No\nHealth Care Coverage                                               Yes\nDoctor Visit Cost Barrier                                           No\nGeneral Health                                               Very Poor\nDifficulty Walking                                                 Yes\nSex                                                             Female\nEducation Level                                   High school graduate\nIncome Level                              $15,000 to less than $20,000\nAge                                                                 64\nVegetable or Fruit Intake (1+ per Day)                             Yes\nBMI Category                                                     Obese\nObesity Risk                                                         1\nName: 0, dtype: object"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"df_yes = train_data[train_data['History of HeartDisease or Attack'] == 'Yes'].sample(n=18068, random_state=42)\ndf_no = train_data[train_data['History of HeartDisease or Attack'] == 'No'].sample(n=20000, random_state=42)\ntrain_data = pd.concat([df_yes, df_no], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2025-04-06T13:34:57.416942Z","iopub.execute_input":"2025-04-06T13:34:57.417292Z","iopub.status.idle":"2025-04-06T13:34:57.516760Z","shell.execute_reply.started":"2025-04-06T13:34:57.417266Z","shell.execute_reply":"2025-04-06T13:34:57.515835Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"train_data.head(3)","metadata":{"execution":{"iopub.status.busy":"2025-04-06T13:34:59.223254Z","iopub.execute_input":"2025-04-06T13:34:59.223659Z","iopub.status.idle":"2025-04-06T13:34:59.249362Z","shell.execute_reply.started":"2025-04-06T13:34:59.223622Z","shell.execute_reply":"2025-04-06T13:34:59.247605Z"},"trusted":true},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"             ID History of HeartDisease or Attack High Blood Pressure  \\\n0  train_183649                               Yes                 Yes   \n1  train_001613                               Yes                 Yes   \n2  train_072658                               Yes                  No   \n\n  Told High Cholesterol Cholesterol Checked  Body Mass Index  \\\n0                   Yes                 Yes            26.36   \n1                   Yes                 Yes            26.11   \n2                   Yes                 Yes            26.23   \n\n  Smoked 100+ Cigarettes Diagnosed Stroke Diagnosed Diabetes  \\\n0                     No              Yes                 No   \n1                    Yes              Yes                Yes   \n2                     No               No                 No   \n\n  Heavy Alcohol Consumption  ... Doctor Visit Cost Barrier General Health  \\\n0                        No  ...                        No      Very Poor   \n1                        No  ...                        No           Poor   \n2                        No  ...                       Yes           Poor   \n\n  Difficulty Walking     Sex   Education Level                   Income Level  \\\n0                Yes  Female  College graduate                $75,000 or more   \n1                 No  Female  Some high school  ($10,000 to less than $15,000   \n2                Yes  Female  College graduate                $75,000 or more   \n\n  Age  Vegetable or Fruit Intake (1+ per Day) BMI Category Obesity Risk  \n0  47                                     Yes   Overweight            0  \n1  59                                     Yes   Overweight            0  \n2  58                                     Yes   Overweight            0  \n\n[3 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>History of HeartDisease or Attack</th>\n      <th>High Blood Pressure</th>\n      <th>Told High Cholesterol</th>\n      <th>Cholesterol Checked</th>\n      <th>Body Mass Index</th>\n      <th>Smoked 100+ Cigarettes</th>\n      <th>Diagnosed Stroke</th>\n      <th>Diagnosed Diabetes</th>\n      <th>Heavy Alcohol Consumption</th>\n      <th>...</th>\n      <th>Doctor Visit Cost Barrier</th>\n      <th>General Health</th>\n      <th>Difficulty Walking</th>\n      <th>Sex</th>\n      <th>Education Level</th>\n      <th>Income Level</th>\n      <th>Age</th>\n      <th>Vegetable or Fruit Intake (1+ per Day)</th>\n      <th>BMI Category</th>\n      <th>Obesity Risk</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_183649</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>26.36</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>...</td>\n      <td>No</td>\n      <td>Very Poor</td>\n      <td>Yes</td>\n      <td>Female</td>\n      <td>College graduate</td>\n      <td>$75,000 or more</td>\n      <td>47</td>\n      <td>Yes</td>\n      <td>Overweight</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_001613</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>26.11</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>...</td>\n      <td>No</td>\n      <td>Poor</td>\n      <td>No</td>\n      <td>Female</td>\n      <td>Some high school</td>\n      <td>($10,000 to less than $15,000</td>\n      <td>59</td>\n      <td>Yes</td>\n      <td>Overweight</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_072658</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>26.23</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>Poor</td>\n      <td>Yes</td>\n      <td>Female</td>\n      <td>College graduate</td>\n      <td>$75,000 or more</td>\n      <td>58</td>\n      <td>Yes</td>\n      <td>Overweight</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 21 columns</p>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"train_data['History of HeartDisease or Attack'].value_counts()\n# train_data['General Health'].isna().sum()","metadata":{"execution":{"iopub.status.busy":"2025-04-06T13:35:01.311816Z","iopub.execute_input":"2025-04-06T13:35:01.312165Z","iopub.status.idle":"2025-04-06T13:35:01.320471Z","shell.execute_reply.started":"2025-04-06T13:35:01.312133Z","shell.execute_reply":"2025-04-06T13:35:01.319792Z"},"trusted":true},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"History of HeartDisease or Attack\nNo     20000\nYes    18068\nName: count, dtype: int64"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"# model time","metadata":{}},{"cell_type":"code","source":"save_path = 'best_model'\nhyperparameters = {\n    'GBM': [\n        {'ag_args_fit': {'num_gpus': 0}},  # Train with CPU\n        {'ag_args_fit': {'num_gpus': 1}}   # Train with GPU\n    ],\n    'CAT': [\n        {'ag_args_fit': {'num_gpus': 0}},  # Train with CPU\n        {'ag_args_fit': {'num_gpus': 1}}   # Train with GPU\n    ],\n    'XGB': [\n        {'ag_args_fit': {'num_gpus': 0}},  # Train with CPU\n        {'ag_args_fit': {'num_gpus': 1}}   # Train with GPU\n    ],\n    'RF': [\n        {'ag_args_fit': {'num_gpus': 0}},  # Train with CPU\n        {'ag_args_fit': {'num_gpus': 1}}   # Train with GPU\n    ],\n\n}\ntime_limit=600","metadata":{"execution":{"iopub.status.busy":"2025-04-06T13:37:33.349628Z","iopub.execute_input":"2025-04-06T13:37:33.349930Z","iopub.status.idle":"2025-04-06T13:37:33.355247Z","shell.execute_reply.started":"2025-04-06T13:37:33.349906Z","shell.execute_reply":"2025-04-06T13:37:33.354055Z"},"trusted":true},"outputs":[],"execution_count":23},{"cell_type":"code","source":"predictor = TabularPredictor(label='History of HeartDisease or Attack',\n                            problem_type='binary',\n                            path=save_path,\n                            # eval_metric='f1_macro'\n                            ).fit(\n                                train_data,\n                                presets='best_quality',\n                                hyperparameters=hyperparameters,\n                                time_limit=time_limit\n                            )\nprint(\"Finish!\")","metadata":{"execution":{"iopub.status.busy":"2025-04-06T13:37:35.680355Z","iopub.execute_input":"2025-04-06T13:37:35.680647Z","iopub.status.idle":"2025-04-06T13:43:29.911885Z","shell.execute_reply.started":"2025-04-06T13:37:35.680625Z","shell.execute_reply":"2025-04-06T13:43:29.911154Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Verbosity: 2 (Standard Logging)\n=================== System Info ===================\nAutoGluon Version:  1.2\nPython Version:     3.10.12\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #1 SMP PREEMPT_DYNAMIC Sun Nov 10 10:07:59 UTC 2024\nCPU Count:          4\nMemory Avail:       29.34 GB / 31.35 GB (93.6%)\nDisk Space Avail:   19.50 GB / 19.52 GB (99.9%)\n===================================================\nPresets specified: ['best_quality']\nSetting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\nStack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\nDyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n\tRunning DyStack for up to 150s of the 600s of remaining time (25%).\n\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n2025-04-06 13:37:38,186\tINFO worker.py:1810 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n\t\tContext path: \"/kaggle/working/best_model/ds_sub_fit/sub_fit_ho\"\n\u001b[36m(_dystack pid=298)\u001b[0m Running DyStack sub-fit ...\n\u001b[36m(_dystack pid=298)\u001b[0m Beginning AutoGluon training ... Time limit = 146s\n\u001b[36m(_dystack pid=298)\u001b[0m AutoGluon will save models to \"/kaggle/working/best_model/ds_sub_fit/sub_fit_ho\"\n\u001b[36m(_dystack pid=298)\u001b[0m Train Data Rows:    33838\n\u001b[36m(_dystack pid=298)\u001b[0m Train Data Columns: 20\n\u001b[36m(_dystack pid=298)\u001b[0m Label Column:       History of HeartDisease or Attack\n\u001b[36m(_dystack pid=298)\u001b[0m Problem Type:       binary\n\u001b[36m(_dystack pid=298)\u001b[0m Preprocessing data ...\n\u001b[36m(_dystack pid=298)\u001b[0m Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n\u001b[36m(_dystack pid=298)\u001b[0m \tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n\u001b[36m(_dystack pid=298)\u001b[0m \tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n\u001b[36m(_dystack pid=298)\u001b[0m Using Feature Generators to preprocess the data ...\n\u001b[36m(_dystack pid=298)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n\u001b[36m(_dystack pid=298)\u001b[0m \tAvailable Memory:                    29602.30 MB\n\u001b[36m(_dystack pid=298)\u001b[0m \tTrain Data (Original)  Memory Usage: 35.29 MB (0.1% of available memory)\n\u001b[36m(_dystack pid=298)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n\u001b[36m(_dystack pid=298)\u001b[0m \tStage 1 Generators:\n\u001b[36m(_dystack pid=298)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n\u001b[36m(_dystack pid=298)\u001b[0m \t\t\tNote: Converting 10 features to boolean dtype as they only contain 2 unique values.\n\u001b[36m(_dystack pid=298)\u001b[0m \tStage 2 Generators:\n\u001b[36m(_dystack pid=298)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n\u001b[36m(_dystack pid=298)\u001b[0m \tStage 3 Generators:\n\u001b[36m(_dystack pid=298)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n\u001b[36m(_dystack pid=298)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n\u001b[36m(_dystack pid=298)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n\u001b[36m(_dystack pid=298)\u001b[0m \tStage 4 Generators:\n\u001b[36m(_dystack pid=298)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n\u001b[36m(_dystack pid=298)\u001b[0m \tStage 5 Generators:\n\u001b[36m(_dystack pid=298)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n\u001b[36m(_dystack pid=298)\u001b[0m \tUnused Original Features (Count: 1): ['ID']\n\u001b[36m(_dystack pid=298)\u001b[0m \t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n\u001b[36m(_dystack pid=298)\u001b[0m \t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n\u001b[36m(_dystack pid=298)\u001b[0m \t\tThese features do not need to be present at inference time.\n\u001b[36m(_dystack pid=298)\u001b[0m \t\t('object', []) : 1 | ['ID']\n\u001b[36m(_dystack pid=298)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n\u001b[36m(_dystack pid=298)\u001b[0m \t\t('float', [])  :  1 | ['Body Mass Index']\n\u001b[36m(_dystack pid=298)\u001b[0m \t\t('int', [])    :  2 | ['Age', 'Obesity Risk']\n\u001b[36m(_dystack pid=298)\u001b[0m \t\t('object', []) : 16 | ['High Blood Pressure', 'Told High Cholesterol', 'Cholesterol Checked', 'Smoked 100+ Cigarettes', 'Diagnosed Stroke', ...]\n\u001b[36m(_dystack pid=298)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n\u001b[36m(_dystack pid=298)\u001b[0m \t\t('category', [])  :  7 | ['Told High Cholesterol', 'Diagnosed Diabetes', 'General Health', 'Difficulty Walking', 'Education Level', ...]\n\u001b[36m(_dystack pid=298)\u001b[0m \t\t('float', [])     :  1 | ['Body Mass Index']\n\u001b[36m(_dystack pid=298)\u001b[0m \t\t('int', [])       :  1 | ['Age']\n\u001b[36m(_dystack pid=298)\u001b[0m \t\t('int', ['bool']) : 10 | ['High Blood Pressure', 'Cholesterol Checked', 'Smoked 100+ Cigarettes', 'Diagnosed Stroke', 'Heavy Alcohol Consumption', ...]\n\u001b[36m(_dystack pid=298)\u001b[0m \t0.4s = Fit runtime\n\u001b[36m(_dystack pid=298)\u001b[0m \t19 features in original data used to generate 19 features in processed data.\n\u001b[36m(_dystack pid=298)\u001b[0m \tTrain Data (Processed) Memory Usage: 1.07 MB (0.0% of available memory)\n\u001b[36m(_dystack pid=298)\u001b[0m Data preprocessing and feature engineering runtime = 0.45s ...\n\u001b[36m(_dystack pid=298)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n\u001b[36m(_dystack pid=298)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n\u001b[36m(_dystack pid=298)\u001b[0m User-specified model hyperparameters to be fit:\n\u001b[36m(_dystack pid=298)\u001b[0m {\n\u001b[36m(_dystack pid=298)\u001b[0m \t'GBM': [{'ag_args_fit': {'num_gpus': 0}}, {'ag_args_fit': {'num_gpus': 1}}],\n\u001b[36m(_dystack pid=298)\u001b[0m \t'CAT': [{'ag_args_fit': {'num_gpus': 0}}, {'ag_args_fit': {'num_gpus': 1}}],\n\u001b[36m(_dystack pid=298)\u001b[0m \t'XGB': [{'ag_args_fit': {'num_gpus': 0}}, {'ag_args_fit': {'num_gpus': 1}}],\n\u001b[36m(_dystack pid=298)\u001b[0m \t'RF': [{'ag_args_fit': {'num_gpus': 0}}, {'ag_args_fit': {'num_gpus': 1}}],\n\u001b[36m(_dystack pid=298)\u001b[0m }\n\u001b[36m(_dystack pid=298)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n\u001b[36m(_dystack pid=298)\u001b[0m Fitting 8 L1 models, fit_strategy=\"sequential\" ...\n\u001b[36m(_dystack pid=298)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 97.04s of the 145.59s of remaining time.\n\u001b[36m(_dystack pid=298)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n\u001b[36m(_dystack pid=298)\u001b[0m \t0.7879\t = Validation score   (accuracy)\n\u001b[36m(_dystack pid=298)\u001b[0m \t11.54s\t = Training   runtime\n\u001b[36m(_dystack pid=298)\u001b[0m \t0.69s\t = Validation runtime\n\u001b[36m(_dystack pid=298)\u001b[0m Fitting model: LightGBM_2_BAG_L1 ... Training model for up to 82.36s of the 130.91s of remaining time.\n\u001b[36m(_dystack pid=298)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.04%)\n\u001b[36m(_ray_fit pid=778)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n\u001b[36m(_ray_fit pid=853)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n\u001b[36m(_ray_fit pid=935)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(_ray_fit pid=1042)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(_dystack pid=298)\u001b[0m \t0.7879\t = Validation score   (accuracy)\n\u001b[36m(_dystack pid=298)\u001b[0m \t18.12s\t = Training   runtime\n\u001b[36m(_dystack pid=298)\u001b[0m \t0.42s\t = Validation runtime\n\u001b[36m(_dystack pid=298)\u001b[0m Fitting model: RandomForest_BAG_L1 ... Training model for up to 61.08s of the 109.64s of remaining time.\n\u001b[36m(_dystack pid=298)\u001b[0m \t0.7716\t = Validation score   (accuracy)\n\u001b[36m(_dystack pid=298)\u001b[0m \t5.36s\t = Training   runtime\n\u001b[36m(_dystack pid=298)\u001b[0m \t1.45s\t = Validation runtime\n\u001b[36m(_dystack pid=298)\u001b[0m Fitting model: RandomForest_2_BAG_L1 ... Training model for up to 53.39s of the 101.94s of remaining time.\n\u001b[36m(_dystack pid=298)\u001b[0m \t0.7716\t = Validation score   (accuracy)\n\u001b[36m(_dystack pid=298)\u001b[0m \t5.11s\t = Training   runtime\n\u001b[36m(_dystack pid=298)\u001b[0m \t1.44s\t = Validation runtime\n\u001b[36m(_dystack pid=298)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 46.07s of the 94.63s of remaining time.\n\u001b[36m(_dystack pid=298)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.05%)\n\u001b[36m(_ray_fit pid=1122)\u001b[0m \tRan out of time, early stopping on iteration 189.\n\u001b[36m(_ray_fit pid=1310)\u001b[0m \tRan out of time, early stopping on iteration 228.\n\u001b[36m(_dystack pid=298)\u001b[0m \t0.7881\t = Validation score   (accuracy)\n\u001b[36m(_dystack pid=298)\u001b[0m \t35.86s\t = Training   runtime\n\u001b[36m(_dystack pid=298)\u001b[0m \t0.08s\t = Validation runtime\n\u001b[36m(_dystack pid=298)\u001b[0m Fitting model: CatBoost_2_BAG_L1 ... Training model for up to 7.03s of the 55.58s of remaining time.\n\u001b[36m(_dystack pid=298)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.06%)\n\u001b[36m(_ray_fit pid=1461)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n\u001b[36m(_ray_fit pid=1461)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n\u001b[36m(_dystack pid=298)\u001b[0m Failed to unpickle serialized exception\n\u001b[36m(_dystack pid=298)\u001b[0m Traceback (most recent call last):\n\u001b[36m(_dystack pid=298)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/exceptions.py\", line 51, in from_ray_exception\n\u001b[36m(_dystack pid=298)\u001b[0m     return pickle.loads(ray_exception.serialized_exception)\n\u001b[36m(_dystack pid=298)\u001b[0m ModuleNotFoundError: No module named '_catboost'\n\u001b[36m(_dystack pid=298)\u001b[0m \n\u001b[36m(_dystack pid=298)\u001b[0m The above exception was the direct cause of the following exception:\n\u001b[36m(_dystack pid=298)\u001b[0m \n\u001b[36m(_dystack pid=298)\u001b[0m Traceback (most recent call last):\n\u001b[36m(_dystack pid=298)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 460, in deserialize_objects\n\u001b[36m(_dystack pid=298)\u001b[0m     obj = self._deserialize_object(data, metadata, object_ref)\n\u001b[36m(_dystack pid=298)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 342, in _deserialize_object\n\u001b[36m(_dystack pid=298)\u001b[0m     return RayError.from_bytes(obj)\n\u001b[36m(_dystack pid=298)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/exceptions.py\", line 45, in from_bytes\n\u001b[36m(_dystack pid=298)\u001b[0m     return RayError.from_ray_exception(ray_exception)\n\u001b[36m(_dystack pid=298)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/exceptions.py\", line 54, in from_ray_exception\n\u001b[36m(_dystack pid=298)\u001b[0m     raise RuntimeError(msg) from e\n\u001b[36m(_dystack pid=298)\u001b[0m RuntimeError: Failed to unpickle serialized exception\n\u001b[36m(_dystack pid=298)\u001b[0m \tWarning: Exception caused CatBoost_2_BAG_L1 to fail during training... Skipping this model.\n\u001b[36m(_dystack pid=298)\u001b[0m \t\tSystem error: Failed to unpickle serialized exception\n\u001b[36m(_dystack pid=298)\u001b[0m traceback: Traceback (most recent call last):\n\u001b[36m(_dystack pid=298)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/exceptions.py\", line 51, in from_ray_exception\n\u001b[36m(_dystack pid=298)\u001b[0m     return pickle.loads(ray_exception.serialized_exception)\n\u001b[36m(_dystack pid=298)\u001b[0m ModuleNotFoundError: No module named '_catboost'\n\u001b[36m(_dystack pid=298)\u001b[0m \n\u001b[36m(_dystack pid=298)\u001b[0m The above exception was the direct cause of the following exception:\n\u001b[36m(_dystack pid=298)\u001b[0m \n\u001b[36m(_dystack pid=298)\u001b[0m Traceback (most recent call last):\n\u001b[36m(_dystack pid=298)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 460, in deserialize_objects\n\u001b[36m(_dystack pid=298)\u001b[0m     obj = self._deserialize_object(data, metadata, object_ref)\n\u001b[36m(_dystack pid=298)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 342, in _deserialize_object\n\u001b[36m(_dystack pid=298)\u001b[0m     return RayError.from_bytes(obj)\n\u001b[36m(_dystack pid=298)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/exceptions.py\", line 45, in from_bytes\n\u001b[36m(_dystack pid=298)\u001b[0m     return RayError.from_ray_exception(ray_exception)\n\u001b[36m(_dystack pid=298)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/exceptions.py\", line 54, in from_ray_exception\n\u001b[36m(_dystack pid=298)\u001b[0m     raise RuntimeError(msg) from e\n\u001b[36m(_dystack pid=298)\u001b[0m RuntimeError: Failed to unpickle serialized exception\n\u001b[36m(_dystack pid=298)\u001b[0m \n\u001b[36m(_dystack pid=298)\u001b[0m Detailed Traceback:\n\u001b[36m(_dystack pid=298)\u001b[0m Traceback (most recent call last):\n\u001b[36m(_dystack pid=298)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n\u001b[36m(_dystack pid=298)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n\u001b[36m(_dystack pid=298)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n\u001b[36m(_dystack pid=298)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n\u001b[36m(_dystack pid=298)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 925, in fit\n\u001b[36m(_dystack pid=298)\u001b[0m     out = self._fit(**kwargs)\n\u001b[36m(_dystack pid=298)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n\u001b[36m(_dystack pid=298)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n\u001b[36m(_dystack pid=298)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 298, in _fit\n\u001b[36m(_dystack pid=298)\u001b[0m     self._fit_folds(\n\u001b[36m(_dystack pid=298)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 724, in _fit_folds\n\u001b[36m(_dystack pid=298)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n\u001b[36m(_dystack pid=298)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n\u001b[36m(_dystack pid=298)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n\u001b[36m(_dystack pid=298)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n\u001b[36m(_dystack pid=298)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n\u001b[36m(_dystack pid=298)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n\u001b[36m(_dystack pid=298)\u001b[0m     raise processed_exception\n\u001b[36m(_dystack pid=298)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n\u001b[36m(_dystack pid=298)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n\u001b[36m(_dystack pid=298)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n\u001b[36m(_dystack pid=298)\u001b[0m     return fn(*args, **kwargs)\n\u001b[36m(_dystack pid=298)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n\u001b[36m(_dystack pid=298)\u001b[0m     return func(*args, **kwargs)\n\u001b[36m(_dystack pid=298)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n\u001b[36m(_dystack pid=298)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n\u001b[36m(_dystack pid=298)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 906, in get_objects\n\u001b[36m(_dystack pid=298)\u001b[0m     raise value\n\u001b[36m(_dystack pid=298)\u001b[0m ray.exceptions.RaySystemError: System error: Failed to unpickle serialized exception\n\u001b[36m(_dystack pid=298)\u001b[0m traceback: Traceback (most recent call last):\n\u001b[36m(_dystack pid=298)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/exceptions.py\", line 51, in from_ray_exception\n\u001b[36m(_dystack pid=298)\u001b[0m     return pickle.loads(ray_exception.serialized_exception)\n\u001b[36m(_dystack pid=298)\u001b[0m ModuleNotFoundError: No module named '_catboost'\n\u001b[36m(_dystack pid=298)\u001b[0m \n\u001b[36m(_dystack pid=298)\u001b[0m The above exception was the direct cause of the following exception:\n\u001b[36m(_dystack pid=298)\u001b[0m \n\u001b[36m(_dystack pid=298)\u001b[0m Traceback (most recent call last):\n\u001b[36m(_dystack pid=298)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 460, in deserialize_objects\n\u001b[36m(_dystack pid=298)\u001b[0m     obj = self._deserialize_object(data, metadata, object_ref)\n\u001b[36m(_dystack pid=298)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/_private/serialization.py\", line 342, in _deserialize_object\n\u001b[36m(_dystack pid=298)\u001b[0m     return RayError.from_bytes(obj)\n\u001b[36m(_dystack pid=298)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/exceptions.py\", line 45, in from_bytes\n\u001b[36m(_dystack pid=298)\u001b[0m     return RayError.from_ray_exception(ray_exception)\n\u001b[36m(_dystack pid=298)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/exceptions.py\", line 54, in from_ray_exception\n\u001b[36m(_dystack pid=298)\u001b[0m     raise RuntimeError(msg) from e\n\u001b[36m(_dystack pid=298)\u001b[0m RuntimeError: Failed to unpickle serialized exception\n\u001b[36m(_dystack pid=298)\u001b[0m \n\u001b[36m(_dystack pid=298)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 3.52s of the 52.07s of remaining time.\n\u001b[36m(_dystack pid=298)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n\u001b[36m(_dystack pid=298)\u001b[0m \t0.7826\t = Validation score   (accuracy)\n\u001b[36m(_dystack pid=298)\u001b[0m \t6.48s\t = Training   runtime\n\u001b[36m(_dystack pid=298)\u001b[0m \t0.25s\t = Validation runtime\n\u001b[36m(_dystack pid=298)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 145.59s of the 42.67s of remaining time.\n\u001b[36m(_ray_fit pid=1462)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n\u001b[36m(_ray_fit pid=1462)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n\u001b[36m(_dystack pid=298)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L1': 0.76, 'LightGBM_BAG_L1': 0.24}\n\u001b[36m(_dystack pid=298)\u001b[0m \t0.7884\t = Validation score   (accuracy)\n\u001b[36m(_dystack pid=298)\u001b[0m \t0.34s\t = Training   runtime\n\u001b[36m(_dystack pid=298)\u001b[0m \t0.0s\t = Validation runtime\n\u001b[36m(_dystack pid=298)\u001b[0m Fitting 8 L2 models, fit_strategy=\"sequential\" ...\n\u001b[36m(_dystack pid=298)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 42.31s of the 42.30s of remaining time.\n\u001b[36m(_dystack pid=298)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n\u001b[36m(_dystack pid=298)\u001b[0m \t0.7888\t = Validation score   (accuracy)\n\u001b[36m(_dystack pid=298)\u001b[0m \t11.44s\t = Training   runtime\n\u001b[36m(_dystack pid=298)\u001b[0m \t0.19s\t = Validation runtime\n\u001b[36m(_dystack pid=298)\u001b[0m Fitting model: LightGBM_2_BAG_L2 ... Training model for up to 27.96s of the 27.95s of remaining time.\n\u001b[36m(_dystack pid=298)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.07%)\n\u001b[36m(_ray_fit pid=2084)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n\u001b[36m(_ray_fit pid=2239)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(_ray_fit pid=2346)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(_dystack pid=298)\u001b[0m \t0.7888\t = Validation score   (accuracy)\n\u001b[36m(_dystack pid=298)\u001b[0m \t16.6s\t = Training   runtime\n\u001b[36m(_dystack pid=298)\u001b[0m \t0.16s\t = Validation runtime\n\u001b[36m(_dystack pid=298)\u001b[0m Fitting model: RandomForest_BAG_L2 ... Training model for up to 9.09s of the 9.08s of remaining time.\n\u001b[36m(_dystack pid=298)\u001b[0m \t0.7864\t = Validation score   (accuracy)\n\u001b[36m(_dystack pid=298)\u001b[0m \t10.05s\t = Training   runtime\n\u001b[36m(_dystack pid=298)\u001b[0m \t1.43s\t = Validation runtime\n\u001b[36m(_dystack pid=298)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 145.59s of the -2.88s of remaining time.\n\u001b[36m(_dystack pid=298)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L2': 0.5, 'RandomForest_BAG_L2': 0.3, 'LightGBM_2_BAG_L1': 0.2}\n\u001b[36m(_dystack pid=298)\u001b[0m \t0.7891\t = Validation score   (accuracy)\n\u001b[36m(_dystack pid=298)\u001b[0m \t0.36s\t = Training   runtime\n\u001b[36m(_dystack pid=298)\u001b[0m \t0.0s\t = Validation runtime\n\u001b[36m(_dystack pid=298)\u001b[0m AutoGluon training complete, total runtime = 149.31s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1944.5 rows/s (4230 batch size)\n\u001b[36m(_dystack pid=298)\u001b[0m Enabling decision threshold calibration (calibrate_decision_threshold='auto', metric is valid, problem_type is 'binary')\n\u001b[36m(_dystack pid=298)\u001b[0m Calibrating decision threshold to optimize metric accuracy | Checking 51 thresholds...\n\u001b[36m(_dystack pid=298)\u001b[0m Calibrating decision threshold via fine-grained search | Checking 38 thresholds...\n\u001b[36m(_dystack pid=298)\u001b[0m \tBase Threshold: 0.500\t| val: 0.7891\n\u001b[36m(_dystack pid=298)\u001b[0m \tBest Threshold: 0.500\t| val: 0.7891\n\u001b[36m(_dystack pid=298)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/best_model/ds_sub_fit/sub_fit_ho\")\n\u001b[36m(_dystack pid=298)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\nLeaderboard on holdout data (DyStack):\n                    model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n0       LightGBM_2_BAG_L2       0.771631   0.788788    accuracy        2.553380       4.488223   99.082131                 0.079638                0.162200          16.604548            2       True          9\n1     WeightedEnsemble_L2       0.770449   0.788374    accuracy        0.641768       0.780897   47.738500                 0.002040                0.002979           0.336034            2       True          7\n2         LightGBM_BAG_L2       0.769976   0.788788    accuracy        2.548235       4.518299   93.914593                 0.074493                0.192276          11.437010            2       True          8\n3     WeightedEnsemble_L3       0.769504   0.789083    accuracy        3.034485       5.946349  104.328841                 0.002519                0.002300           0.364897            3       True         11\n4         CatBoost_BAG_L1       0.769267   0.788138    accuracy        0.321038       0.083929   35.864326                 0.321038                0.083929          35.864326            1       True          5\n5          XGBoost_BAG_L1       0.767612   0.782611    accuracy        0.185121       0.246114    6.483115                 0.185121                0.246114           6.483115            1       True          6\n6       LightGBM_2_BAG_L1       0.767612   0.787872    accuracy        0.203895       0.420288   18.122168                 0.203895                0.420288          18.122168            1       True          2\n7         LightGBM_BAG_L1       0.767612   0.787872    accuracy        0.318691       0.693990   11.538139                 0.318691                0.693990          11.538139            1       True          1\n8     RandomForest_BAG_L2       0.766194   0.786364    accuracy        2.957473       5.751773   92.526935                 0.483731                1.425750          10.049351            2       True         10\n9     RandomForest_BAG_L1       0.755792   0.771588    accuracy        0.710853       1.445886    5.357412                 0.710853                1.445886           5.357412            1       True          3\n10  RandomForest_2_BAG_L1       0.755792   0.771588    accuracy        0.734145       1.435817    5.112422                 0.734145                1.435817           5.112422            1       True          4\n\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n\t159s\t = DyStack   runtime |\t441s\t = Remaining runtime\nStarting main fit with num_stack_levels=0.\n\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\nBeginning AutoGluon training ... Time limit = 441s\nAutoGluon will save models to \"/kaggle/working/best_model\"\nTrain Data Rows:    38068\nTrain Data Columns: 20\nLabel Column:       History of HeartDisease or Attack\nProblem Type:       binary\nPreprocessing data ...\nSelected class <--> label mapping:  class 1 = Yes, class 0 = No\n\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n\tAvailable Memory:                    29159.76 MB\n\tTrain Data (Original)  Memory Usage: 39.82 MB (0.1% of available memory)\n\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n\tStage 1 Generators:\n\t\tFitting AsTypeFeatureGenerator...\n\t\t\tNote: Converting 10 features to boolean dtype as they only contain 2 unique values.\n\tStage 2 Generators:\n\t\tFitting FillNaFeatureGenerator...\n\tStage 3 Generators:\n\t\tFitting IdentityFeatureGenerator...\n\t\tFitting CategoryFeatureGenerator...\n\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n\tStage 4 Generators:\n\t\tFitting DropUniqueFeatureGenerator...\n\tStage 5 Generators:\n\t\tFitting DropDuplicatesFeatureGenerator...\n\tUnused Original Features (Count: 1): ['ID']\n\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n\t\tThese features do not need to be present at inference time.\n\t\t('object', []) : 1 | ['ID']\n\tTypes of features in original data (raw dtype, special dtypes):\n\t\t('float', [])  :  1 | ['Body Mass Index']\n\t\t('int', [])    :  2 | ['Age', 'Obesity Risk']\n\t\t('object', []) : 16 | ['High Blood Pressure', 'Told High Cholesterol', 'Cholesterol Checked', 'Smoked 100+ Cigarettes', 'Diagnosed Stroke', ...]\n\tTypes of features in processed data (raw dtype, special dtypes):\n\t\t('category', [])  :  7 | ['Told High Cholesterol', 'Diagnosed Diabetes', 'General Health', 'Difficulty Walking', 'Education Level', ...]\n\t\t('float', [])     :  1 | ['Body Mass Index']\n\t\t('int', [])       :  1 | ['Age']\n\t\t('int', ['bool']) : 10 | ['High Blood Pressure', 'Cholesterol Checked', 'Smoked 100+ Cigarettes', 'Diagnosed Stroke', 'Heavy Alcohol Consumption', ...]\n\t0.5s = Fit runtime\n\t19 features in original data used to generate 19 features in processed data.\n\tTrain Data (Processed) Memory Usage: 1.20 MB (0.0% of available memory)\nData preprocessing and feature engineering runtime = 0.62s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n\tTo change this, specify the eval_metric parameter of Predictor()\nUser-specified model hyperparameters to be fit:\n{\n\t'GBM': [{'ag_args_fit': {'num_gpus': 0}}, {'ag_args_fit': {'num_gpus': 1}}],\n\t'CAT': [{'ag_args_fit': {'num_gpus': 0}}, {'ag_args_fit': {'num_gpus': 1}}],\n\t'XGB': [{'ag_args_fit': {'num_gpus': 0}}, {'ag_args_fit': {'num_gpus': 1}}],\n\t'RF': [{'ag_args_fit': {'num_gpus': 0}}, {'ag_args_fit': {'num_gpus': 1}}],\n}\nFitting 8 L1 models, fit_strategy=\"sequential\" ...\nFitting model: LightGBM_BAG_L1 ... Training model for up to 440.71s of the 440.71s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.04%)\n\t0.7864\t = Validation score   (accuracy)\n\t10.88s\t = Training   runtime\n\t0.48s\t = Validation runtime\nFitting model: LightGBM_2_BAG_L1 ... Training model for up to 426.88s of the 426.88s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.04%)\n\t0.7864\t = Validation score   (accuracy)\n\t17.06s\t = Training   runtime\n\t0.3s\t = Validation runtime\nFitting model: RandomForest_BAG_L1 ... Training model for up to 407.45s of the 407.45s of remaining time.\n\t0.7694\t = Validation score   (accuracy)\n\t5.87s\t = Training   runtime\n\t1.61s\t = Validation runtime\nFitting model: RandomForest_2_BAG_L1 ... Training model for up to 399.11s of the 399.11s of remaining time.\n\t0.7694\t = Validation score   (accuracy)\n\t5.54s\t = Training   runtime\n\t1.61s\t = Validation runtime\nFitting model: CatBoost_BAG_L1 ... Training model for up to 391.09s of the 391.09s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.05%)\n\t0.7867\t = Validation score   (accuracy)\n\t59.69s\t = Training   runtime\n\t0.1s\t = Validation runtime\nFitting model: CatBoost_2_BAG_L1 ... Training model for up to 328.62s of the 328.62s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.05%)\n\t0.7866\t = Validation score   (accuracy)\n\t47.9s\t = Training   runtime\n\t0.1s\t = Validation runtime\nFitting model: XGBoost_BAG_L1 ... Training model for up to 278.75s of the 278.75s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.06%)\n\t0.7846\t = Validation score   (accuracy)\n\t15.75s\t = Training   runtime\n\t0.47s\t = Validation runtime\nFitting model: XGBoost_2_BAG_L1 ... Training model for up to 260.00s of the 260.00s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=0.06%)\n\t0.785\t = Validation score   (accuracy)\n\t11.23s\t = Training   runtime\n\t0.15s\t = Validation runtime\nFitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 246.78s of remaining time.\n\tEnsemble Weights: {'CatBoost_BAG_L1': 1.0}\n\t0.7867\t = Validation score   (accuracy)\n\t0.68s\t = Training   runtime\n\t0.0s\t = Validation runtime\nAutoGluon training complete, total runtime = 195.27s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 47419.7 rows/s (4759 batch size)\nEnabling decision threshold calibration (calibrate_decision_threshold='auto', metric is valid, problem_type is 'binary')\nCalibrating decision threshold to optimize metric accuracy | Checking 51 thresholds...\nCalibrating decision threshold via fine-grained search | Checking 38 thresholds...\n\tBase Threshold: 0.500\t| val: 0.7867\n\tBest Threshold: 0.500\t| val: 0.7867\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/best_model\")\n","output_type":"stream"},{"name":"stdout","text":"Finish!\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"# test data","metadata":{}},{"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/hearth-disease-recognition/test.csv\")\ntest_data.head()","metadata":{"execution":{"iopub.status.busy":"2025-04-06T13:44:17.345265Z","iopub.execute_input":"2025-04-06T13:44:17.345582Z","iopub.status.idle":"2025-04-06T13:44:17.511594Z","shell.execute_reply.started":"2025-04-06T13:44:17.345553Z","shell.execute_reply":"2025-04-06T13:44:17.510675Z"},"trusted":true},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"            ID High Blood Pressure Told High Cholesterol Cholesterol Checked  \\\n0  test_000001                 Yes                   Yes                 Yes   \n1  test_000002                 Yes                    No                 Yes   \n2  test_000003                 Yes                   Yes                 Yes   \n3  test_000004                  No                    No                 Yes   \n4  test_000005                  No                    No                 Yes   \n\n   Body Mass Index Smoked 100+ Cigarettes Diagnosed Stroke Diagnosed Diabetes  \\\n0            24.84                     No               No                 No   \n1            29.08                    Yes               No                 No   \n2            35.23                    Yes               No                 No   \n3            24.78                    Yes               No                 No   \n4            27.57                    Yes               No                 No   \n\n  Leisure Physical Activity Heavy Alcohol Consumption Health Care Coverage  \\\n0                       Yes                        No                  Yes   \n1                        No                        No                  Yes   \n2                        No                        No                  Yes   \n3                        No                        No                  Yes   \n4                        No                        No                  Yes   \n\n  Doctor Visit Cost Barrier General Health Difficulty Walking     Sex  \\\n0                        No           Good                 No  Female   \n1                        No           Fair                 No  Female   \n2                        No           Fair                Yes  Female   \n3                        No           Fair                 No  Female   \n4                        No           Fair                 No    Male   \n\n                    Education Level                  Income Level  Age  \\\n0  Some college or technical school  $20,000 to less than $25,000   71   \n1                  College graduate  $50,000 to less than $75,000   61   \n2  Some college or technical school             Less than $10,000   67   \n3  Some college or technical school  $50,000 to less than $75,000   50   \n4  Some college or technical school  $25,000 to less than $35,000   40   \n\n  Vegetable or Fruit Intake (1+ per Day)  \n0                                    Yes  \n1                                     No  \n2                                    Yes  \n3                                    Yes  \n4                                    Yes  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>High Blood Pressure</th>\n      <th>Told High Cholesterol</th>\n      <th>Cholesterol Checked</th>\n      <th>Body Mass Index</th>\n      <th>Smoked 100+ Cigarettes</th>\n      <th>Diagnosed Stroke</th>\n      <th>Diagnosed Diabetes</th>\n      <th>Leisure Physical Activity</th>\n      <th>Heavy Alcohol Consumption</th>\n      <th>Health Care Coverage</th>\n      <th>Doctor Visit Cost Barrier</th>\n      <th>General Health</th>\n      <th>Difficulty Walking</th>\n      <th>Sex</th>\n      <th>Education Level</th>\n      <th>Income Level</th>\n      <th>Age</th>\n      <th>Vegetable or Fruit Intake (1+ per Day)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_000001</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>24.84</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Good</td>\n      <td>No</td>\n      <td>Female</td>\n      <td>Some college or technical school</td>\n      <td>$20,000 to less than $25,000</td>\n      <td>71</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_000002</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>29.08</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Fair</td>\n      <td>No</td>\n      <td>Female</td>\n      <td>College graduate</td>\n      <td>$50,000 to less than $75,000</td>\n      <td>61</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_000003</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>35.23</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Fair</td>\n      <td>Yes</td>\n      <td>Female</td>\n      <td>Some college or technical school</td>\n      <td>Less than $10,000</td>\n      <td>67</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_000004</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>24.78</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Fair</td>\n      <td>No</td>\n      <td>Female</td>\n      <td>Some college or technical school</td>\n      <td>$50,000 to less than $75,000</td>\n      <td>50</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_000005</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>27.57</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Fair</td>\n      <td>No</td>\n      <td>Male</td>\n      <td>Some college or technical school</td>\n      <td>$25,000 to less than $35,000</td>\n      <td>40</td>\n      <td>Yes</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"for i in test_data.columns:\n    print(i, end=\" \")\n    print(test_data[i].isna().sum())","metadata":{"execution":{"iopub.status.busy":"2025-04-06T13:44:20.199287Z","iopub.execute_input":"2025-04-06T13:44:20.199570Z","iopub.status.idle":"2025-04-06T13:44:20.267708Z","shell.execute_reply.started":"2025-04-06T13:44:20.199549Z","shell.execute_reply":"2025-04-06T13:44:20.267057Z"},"trusted":true},"outputs":[{"name":"stdout","text":"ID 0\nHigh Blood Pressure 0\nTold High Cholesterol 0\nCholesterol Checked 0\nBody Mass Index 0\nSmoked 100+ Cigarettes 0\nDiagnosed Stroke 0\nDiagnosed Diabetes 0\nLeisure Physical Activity 0\nHeavy Alcohol Consumption 0\nHealth Care Coverage 0\nDoctor Visit Cost Barrier 0\nGeneral Health 0\nDifficulty Walking 0\nSex 0\nEducation Level 0\nIncome Level 0\nAge 0\nVegetable or Fruit Intake (1+ per Day) 0\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# preprocess test\ntest_data = create_new_features(test_data)","metadata":{"execution":{"iopub.status.busy":"2025-04-06T13:44:22.372442Z","iopub.execute_input":"2025-04-06T13:44:22.372761Z","iopub.status.idle":"2025-04-06T13:44:22.457041Z","shell.execute_reply.started":"2025-04-06T13:44:22.372732Z","shell.execute_reply":"2025-04-06T13:44:22.456061Z"},"trusted":true},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# y_pred = predictor.predict(test_data)\n# y_pred.head() predict_proba\n\n# use proba\ny_pred = predictor.predict_proba(test_data)\ny_pred.head()","metadata":{"execution":{"iopub.status.busy":"2025-04-06T13:44:25.568468Z","iopub.execute_input":"2025-04-06T13:44:25.568781Z","iopub.status.idle":"2025-04-06T13:44:26.158416Z","shell.execute_reply.started":"2025-04-06T13:44:25.568754Z","shell.execute_reply":"2025-04-06T13:44:26.157579Z"},"trusted":true},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"         No       Yes\n0  0.540053  0.459947\n1  0.676904  0.323096\n2  0.302197  0.697803\n3  0.863165  0.136835\n4  0.848005  0.151995","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>No</th>\n      <th>Yes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.540053</td>\n      <td>0.459947</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.676904</td>\n      <td>0.323096</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.302197</td>\n      <td>0.697803</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.863165</td>\n      <td>0.136835</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.848005</td>\n      <td>0.151995</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"y_pred['outcome'] = y_pred.apply(lambda row: 'Yes' if row['Yes'] > 0.505 else 'No', axis=1)\ny_pred['outcome'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2025-04-06T13:44:29.448819Z","iopub.execute_input":"2025-04-06T13:44:29.449152Z","iopub.status.idle":"2025-04-06T13:44:29.812081Z","shell.execute_reply.started":"2025-04-06T13:44:29.449124Z","shell.execute_reply":"2025-04-06T13:44:29.811408Z"},"trusted":true},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"outcome\nNo     50155\nYes    24206\nName: count, dtype: int64"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"sample_submission = pd.read_csv(\"/kaggle/input/hearth-disease-recognition/sample_submission.csv\")\nsample_submission.head(2)","metadata":{"execution":{"iopub.status.busy":"2025-04-06T13:44:32.446263Z","iopub.execute_input":"2025-04-06T13:44:32.446580Z","iopub.status.idle":"2025-04-06T13:44:32.506854Z","shell.execute_reply.started":"2025-04-06T13:44:32.446558Z","shell.execute_reply":"2025-04-06T13:44:32.505775Z"},"trusted":true},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"            ID History of HeartDisease or Attack\n0  test_000001                                No\n1  test_000002                                No","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>History of HeartDisease or Attack</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_000001</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_000002</td>\n      <td>No</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"# sample_submission['History of HeartDisease or Attack'] = y_pred\nsample_submission['History of HeartDisease or Attack'] = y_pred['outcome']\nsample_submission.tail()","metadata":{"execution":{"iopub.status.busy":"2025-04-06T13:44:36.696216Z","iopub.execute_input":"2025-04-06T13:44:36.696550Z","iopub.status.idle":"2025-04-06T13:44:36.705779Z","shell.execute_reply.started":"2025-04-06T13:44:36.696519Z","shell.execute_reply":"2025-04-06T13:44:36.704821Z"},"trusted":true},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"                ID History of HeartDisease or Attack\n74356  test_074357                                No\n74357  test_074358                               Yes\n74358  test_074359                               Yes\n74359  test_074360                               Yes\n74360  test_074361                                No","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>History of HeartDisease or Attack</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>74356</th>\n      <td>test_074357</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>74357</th>\n      <td>test_074358</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>74358</th>\n      <td>test_074359</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>74359</th>\n      <td>test_074360</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>74360</th>\n      <td>test_074361</td>\n      <td>No</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"# sample_submission.to_csv(\"preprocess_first__no_prepare_52_7%confident_Accuracy_train20k_20k.csv\", index=False)\nsample_submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2025-04-06T13:45:13.853465Z","iopub.execute_input":"2025-04-06T13:45:13.853791Z","iopub.status.idle":"2025-04-06T13:45:13.912969Z","shell.execute_reply.started":"2025-04-06T13:45:13.853766Z","shell.execute_reply":"2025-04-06T13:45:13.912308Z"},"trusted":true},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":"# check submission","metadata":{}},{"cell_type":"code","source":"wowow = pd.read_csv(\"/kaggle/working/submission.csv\")\nwowow['History of HeartDisease or Attack'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2025-04-06T13:45:44.211375Z","iopub.execute_input":"2025-04-06T13:45:44.211667Z","iopub.status.idle":"2025-04-06T13:45:44.254054Z","shell.execute_reply.started":"2025-04-06T13:45:44.211645Z","shell.execute_reply":"2025-04-06T13:45:44.253185Z"},"trusted":true},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"History of HeartDisease or Attack\nNo     50155\nYes    24206\nName: count, dtype: int64"},"metadata":{}}],"execution_count":34}]}