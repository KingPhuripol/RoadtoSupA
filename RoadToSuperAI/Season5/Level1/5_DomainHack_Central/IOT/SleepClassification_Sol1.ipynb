{"cells":[{"cell_type":"code","execution_count":null,"id":"b18766ba-4077-467d-83f7-033bfd67cc80","metadata":{"id":"b18766ba-4077-467d-83f7-033bfd67cc80"},"outputs":[],"source":["from scipy.stats import skew, kurtosis\n","\n","def safe_skew(series):\n","    try:\n","        if series.nunique() > 1 and np.std(series) > 1e-6:\n","            return skew(series)\n","        return 0  # Default if too little variation\n","    except RuntimeWarning:\n","        return 0  # Ignore and return 0\n","\n","def safe_kurtosis(series):\n","    try:\n","        if series.nunique() > 1 and np.std(series) > 1e-6:\n","            return kurtosis(series)\n","        return 0\n","    except RuntimeWarning:\n","        return 0"]},{"cell_type":"code","execution_count":null,"id":"ef914679-7a9d-4f76-8adb-ff533da54258","metadata":{"scrolled":true,"id":"ef914679-7a9d-4f76-8adb-ff533da54258","outputId":"1d4974eb-63e2-4f0e-b5ab-e4f75b1778e6"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Feature extraction complete!\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from scipy.stats import skew, kurtosis\n","import glob  # For handling file paths efficiently\n","\n","paths_train = glob.glob('train/*.csv')  # Get all CSV file paths\n","prepare_data = []\n","\n","for count, path in enumerate(paths_train):\n","    df_train = pd.read_csv(path)\n","\n","    for i in range(int(len(df_train) / 480)):\n","        df_chunk = df_train.iloc[480 * i : 480 * (i + 1)]\n","\n","        # Acceleration features\n","        std_x = df_chunk['ACC_X'].std()\n","        std_y = df_chunk['ACC_Y'].std()\n","        std_z = df_chunk['ACC_Z'].std()\n","        var_x = df_chunk['ACC_X'].var()\n","        var_y = df_chunk['ACC_Y'].var()\n","        var_z = df_chunk['ACC_Z'].var()\n","        skew_x = safe_skew(df_chunk['ACC_X'])\n","        skew_y = safe_skew(df_chunk['ACC_Y'])\n","        skew_z = safe_skew(df_chunk['ACC_Z'])\n","        kurt_x = safe_kurtosis(df_chunk['ACC_X'])\n","        kurt_y = safe_kurtosis(df_chunk['ACC_Y'])\n","        kurt_z = safe_kurtosis(df_chunk['ACC_Z'])\n","\n","        # BVP features\n","        std_bvp = df_chunk['BVP'].std()\n","        mean_bvp = df_chunk['BVP'].mean()\n","        var_bvp = df_chunk['BVP'].var()\n","\n","        # Temperature\n","        mean_temp = df_chunk['TEMP'].mean()\n","        std_temp = df_chunk['TEMP'].std()\n","\n","        # Heart rate\n","        mean_hr = df_chunk['HR'].mean()\n","        std_hr = df_chunk['HR'].std()\n","\n","        # EDA\n","        mean_eda = df_chunk['EDA'].mean()\n","        std_eda = df_chunk['EDA'].std()\n","\n","        # Frequency domain (FFT)\n","        fft_acc_x = np.abs(np.fft.fft(df_chunk['ACC_X']))[:10]  # Take first 10 FFT components\n","        fft_acc_y = np.abs(np.fft.fft(df_chunk['ACC_Y']))[:10]\n","        fft_acc_z = np.abs(np.fft.fft(df_chunk['ACC_Z']))[:10]\n","        fft_bvp = np.abs(np.fft.fft(df_chunk['BVP']))[:10]\n","\n","        # Combine all features\n","        feature_row = [\n","            std_x, std_y, std_z, var_x, var_y, var_z, skew_x, skew_y, skew_z, kurt_x, kurt_y, kurt_z,\n","            std_bvp, mean_bvp, var_bvp, mean_temp, std_temp, mean_hr, std_hr, mean_eda, std_eda\n","        ] + list(fft_acc_x) + list(fft_acc_y) + list(fft_acc_z) + list(fft_bvp)\n","\n","        label = df_chunk['Sleep_Stage'].iloc[0]\n","        prepare_data.append(feature_row + [label])\n","\n","print(\"✅ Feature extraction complete!\")\n"]},{"cell_type":"code","execution_count":null,"id":"66168192-9ee4-43e0-b4c6-05260882d53c","metadata":{"id":"66168192-9ee4-43e0-b4c6-05260882d53c"},"outputs":[],"source":["column_names = [\n","    'std_x', 'std_y', 'std_z', 'var_x', 'var_y', 'var_z',\n","    'skew_x', 'skew_y', 'skew_z', 'kurt_x', 'kurt_y', 'kurt_z',\n","    'std_bvp', 'mean_bvp', 'var_bvp', 'mean_temp', 'std_temp', 'mean_hr', 'std_hr',\n","    'mean_eda', 'std_eda'\n","]\n","\n","for i in range(10):\n","    column_names.append(f'fft_acc_x_{i}')\n","    column_names.append(f'fft_acc_y_{i}')\n","    column_names.append(f'fft_acc_z_{i}')\n","    column_names.append(f'fft_bvp_{i}')\n","\n","column_names.append('label')\n","\n","df_train_ = pd.DataFrame(prepare_data, columns=column_names)"]},{"cell_type":"code","execution_count":null,"id":"a38661cd-9942-446b-aa47-b93d0ed64cda","metadata":{"id":"a38661cd-9942-446b-aa47-b93d0ed64cda"},"outputs":[],"source":["import os\n","\n","paths_test = sorted(glob.glob('test_segment/*'))\n","\n","prepare_data_test = []\n","for paths in paths_test:\n","    sub_paths = os.path.join(paths, \"*\")\n","    sub_paths = sorted(glob.glob(sub_paths))\n","    for sub in sub_paths: # for loop to get each csv\n","        sub_df_test = pd.read_csv(sub)\n","        # Acceleration features\n","        std_x = sub_df_test['ACC_X'].std()\n","        std_y = sub_df_test['ACC_Y'].std()\n","        std_z = sub_df_test['ACC_Z'].std()\n","        var_x = sub_df_test['ACC_X'].var()\n","        var_y = sub_df_test['ACC_Y'].var()\n","        var_z = sub_df_test['ACC_Z'].var()\n","        skew_x = safe_skew(sub_df_test['ACC_X'])\n","        skew_y = safe_skew(sub_df_test['ACC_Y'])\n","        skew_z = safe_skew(sub_df_test['ACC_Z'])\n","        kurt_x = safe_kurtosis(sub_df_test['ACC_X'])\n","        kurt_y = safe_kurtosis(sub_df_test['ACC_Y'])\n","        kurt_z = safe_kurtosis(sub_df_test['ACC_Z'])\n","\n","        # BVP features\n","        std_bvp = sub_df_test['BVP'].std()\n","        mean_bvp = sub_df_test['BVP'].mean()\n","        var_bvp = sub_df_test['BVP'].var()\n","\n","        # Temperature\n","        mean_temp = sub_df_test['TEMP'].mean()\n","        std_temp = sub_df_test['TEMP'].std()\n","\n","        # Heart rate\n","        mean_hr = sub_df_test['HR'].mean()\n","        std_hr = sub_df_test['HR'].std()\n","\n","        # EDA\n","        mean_eda = sub_df_test['EDA'].mean()\n","        std_eda = sub_df_test['EDA'].std()\n","\n","        # Frequency domain (FFT)\n","        fft_acc_x = np.abs(np.fft.fft(sub_df_test['ACC_X']))[:10]  # Take first 10 FFT components\n","        fft_acc_y = np.abs(np.fft.fft(sub_df_test['ACC_Y']))[:10]\n","        fft_acc_z = np.abs(np.fft.fft(sub_df_test['ACC_Z']))[:10]\n","        fft_bvp = np.abs(np.fft.fft(sub_df_test['BVP']))[:10]\n","\n","        # Combine all features\n","        feature_row = [\n","            std_x, std_y, std_z, var_x, var_y, var_z, skew_x, skew_y, skew_z, kurt_x, kurt_y, kurt_z,\n","            std_bvp, mean_bvp, var_bvp, mean_temp, std_temp, mean_hr, std_hr, mean_eda, std_eda\n","        ] + list(fft_acc_x) + list(fft_acc_y) + list(fft_acc_z) + list(fft_bvp)\n","\n","        prepare_data_test.append(feature_row)"]},{"cell_type":"code","execution_count":null,"id":"072ffa80-ff91-4b62-bd83-769a32088415","metadata":{"id":"072ffa80-ff91-4b62-bd83-769a32088415"},"outputs":[],"source":["column_names = [\n","    'std_x', 'std_y', 'std_z', 'var_x', 'var_y', 'var_z',\n","    'skew_x', 'skew_y', 'skew_z', 'kurt_x', 'kurt_y', 'kurt_z',\n","    'std_bvp', 'mean_bvp', 'var_bvp', 'mean_temp', 'std_temp', 'mean_hr', 'std_hr',\n","    'mean_eda', 'std_eda'\n","]\n","\n","for i in range(10):\n","    column_names.append(f'fft_acc_x_{i}')\n","    column_names.append(f'fft_acc_y_{i}')\n","    column_names.append(f'fft_acc_z_{i}')\n","    column_names.append(f'fft_bvp_{i}')\n","\n","df_test_ = pd.DataFrame(prepare_data_test, columns=column_names)"]},{"cell_type":"code","execution_count":null,"id":"9957eb2a-8e2c-45b0-8923-4b2052156865","metadata":{"id":"9957eb2a-8e2c-45b0-8923-4b2052156865"},"outputs":[],"source":["from autogluon.tabular import TabularDataset, TabularPredictor"]},{"cell_type":"code","execution_count":null,"id":"16ec13ee-54d2-45b5-9a69-8b1f1002159e","metadata":{"id":"16ec13ee-54d2-45b5-9a69-8b1f1002159e"},"outputs":[],"source":["save_path = 'best_model'\n","hyperparameters = {\n","    'GBM': [\n","        {'ag_args_fit': {'num_gpus': 0}},  # Train with CPU\n","        {'ag_args_fit': {'num_gpus': 1}}   # Train with GPU\n","    ],\n","    'RF': {},   # Random Forest (helps with imbalanced data)\n","    'XGB': {},  # XGBoost (great for tabular data)\n","    'NN_TORCH': {'num_epochs': 50},  # Neural network (can capture complex patterns)\n","}\n","time_limit=600"]},{"cell_type":"code","execution_count":null,"id":"601cbd9a-4ef0-4325-a264-b57a8e042dbb","metadata":{"id":"601cbd9a-4ef0-4325-a264-b57a8e042dbb","outputId":"793a39c2-2c3b-40ab-dc45-58ebb7159a1c"},"outputs":[{"name":"stderr","output_type":"stream","text":["Warning: path already exists! This predictor may overwrite an existing predictor! path=\"best_model\"\n","Verbosity: 2 (Standard Logging)\n","=================== System Info ===================\n","AutoGluon Version:  1.2\n","Python Version:     3.12.2\n","Operating System:   Darwin\n","Platform Machine:   arm64\n","Platform Version:   Darwin Kernel Version 24.3.0: Thu Jan  2 20:23:36 PST 2025; root:xnu-11215.81.4~3/RELEASE_ARM64_T8112\n","CPU Count:          8\n","Memory Avail:       4.00 GB / 16.00 GB (25.0%)\n","Disk Space Avail:   198.59 GB / 460.43 GB (43.1%)\n","===================================================\n","Presets specified: ['best_quality']\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n","\tRunning DyStack for up to 150s of the 600s of remaining time (25%).\n","\t\tContext path: \"/Users/biocorn/Documents/2025/SuperAI/Hackathon/5_Domain/Sleep Stage Classification/best_model/ds_sub_fit/sub_fit_ho\"\n","Leaderboard on holdout data (DyStack):\n","                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n","0      LightGBM_BAG_L2       0.779021   0.766097    accuracy        5.779274      91.617413  102.500692                 0.227451                1.303853          19.380301            2       True          4\n","1  WeightedEnsemble_L3       0.779021   0.766097    accuracy        5.780112      91.621626  103.396019                 0.000838                0.004213           0.895327            3       True          7\n","2       XGBoost_BAG_L2       0.777268   0.764900    accuracy        5.689901      90.877791   88.396325                 0.138078                0.564231           5.275934            2       True          6\n","3  RandomForest_BAG_L2       0.774976   0.760720    accuracy        5.684211      91.061496  101.376391                 0.132388                0.747936          18.255999            2       True          5\n","4      LightGBM_BAG_L1       0.760820   0.753995    accuracy        5.408458      90.100401   81.225528                 5.408458               90.100401          81.225528            1       True          1\n","5  WeightedEnsemble_L2       0.760820   0.753995    accuracy        5.409752      90.105280   81.545357                 0.001294                0.004879           0.319830            2       True          3\n","6       XGBoost_BAG_L1       0.595524   0.596379    accuracy        0.143365       0.213158    1.894864                 0.143365                0.213158           1.894864            1       True          2\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n","\t160s\t = DyStack   runtime |\t440s\t = Remaining runtime\n","Starting main fit with num_stack_levels=1.\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n","Beginning AutoGluon training ... Time limit = 440s\n","AutoGluon will save models to \"/Users/biocorn/Documents/2025/SuperAI/Hackathon/5_Domain/Sleep Stage Classification/best_model\"\n","Train Data Rows:    66745\n","Train Data Columns: 61\n","Label Column:       label\n","Problem Type:       multiclass\n","Preprocessing data ...\n","Train Data Class Count: 5\n","Using Feature Generators to preprocess the data ...\n","Fitting AutoMLPipelineFeatureGenerator...\n","\tAvailable Memory:                    4466.42 MB\n","\tTrain Data (Original)  Memory Usage: 31.06 MB (0.7% of available memory)\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n","\tStage 1 Generators:\n","\t\tFitting AsTypeFeatureGenerator...\n","\tStage 2 Generators:\n","\t\tFitting FillNaFeatureGenerator...\n","\tStage 3 Generators:\n","\t\tFitting IdentityFeatureGenerator...\n","\tStage 4 Generators:\n","\t\tFitting DropUniqueFeatureGenerator...\n","\tStage 5 Generators:\n","\t\tFitting DropDuplicatesFeatureGenerator...\n","\tTypes of features in original data (raw dtype, special dtypes):\n","\t\t('float', []) : 61 | ['std_x', 'std_y', 'std_z', 'var_x', 'var_y', ...]\n","\tTypes of features in processed data (raw dtype, special dtypes):\n","\t\t('float', []) : 61 | ['std_x', 'std_y', 'std_z', 'var_x', 'var_y', ...]\n","\t0.3s = Fit runtime\n","\t61 features in original data used to generate 61 features in processed data.\n","\tTrain Data (Processed) Memory Usage: 31.06 MB (0.7% of available memory)\n","Data preprocessing and feature engineering runtime = 0.34s ...\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n","\tTo change this, specify the eval_metric parameter of Predictor()\n","User-specified model hyperparameters to be fit:\n","{\n","\t'GBM': [{'ag_args_fit': {'num_gpus': 0}}, {'ag_args_fit': {'num_gpus': 1}}],\n","\t'RF': [{}],\n","\t'XGB': [{}],\n","\t'NN_TORCH': [{'num_epochs': 50}],\n","}\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\n","Fitting 5 L1 models, fit_strategy=\"sequential\" ...\n","Fitting model: LightGBM_BAG_L1 ... Training model for up to 292.81s of the 439.32s of remaining time.\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=5.42%)\n","\t0.7674\t = Validation score   (accuracy)\n","\t237.89s\t = Training   runtime\n","\t206.17s\t = Validation runtime\n","Fitting model: LightGBM_2_BAG_L1 ... Training model for up to 23.80s of the 170.31s of remaining time.\n","\tWarning: Exception caused LightGBM_2_BAG_L1 to fail during training... Skipping this model.\n","\t\tSpecified num_gpus per model base is more than the total: 0\n","Detailed Traceback:\n","Traceback (most recent call last):\n","  File \"/opt/anaconda3/lib/python3.12/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n","    model = self._train_single(**model_fit_kwargs)\n","            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/opt/anaconda3/lib/python3.12/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n","    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n","            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/opt/anaconda3/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 914, in fit\n","    kwargs = self._preprocess_fit_args(**kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/opt/anaconda3/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 566, in _preprocess_fit_args\n","    kwargs = self._preprocess_fit_resources(**kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/opt/anaconda3/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 816, in _preprocess_fit_resources\n","    return self._calculate_total_resources(silent=silent, total_resources=total_resources, parallel_hpo=parallel_hpo, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/opt/anaconda3/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 697, in _calculate_total_resources\n","    user_specified_lower_level_num_gpus = self._process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble(\n","                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/opt/anaconda3/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 642, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n","    assert user_specified_model_level_resource <= system_resource, f\"Specified {resource_type} per model base is more than the total: {system_resource}\"\n","AssertionError: Specified num_gpus per model base is more than the total: 0\n","Fitting model: RandomForest_BAG_L1 ... Training model for up to 23.27s of the 169.78s of remaining time.\n","\tWarning: Reducing model 'n_estimators' from 300 -> 108 due to low time. Expected time usage reduced from 63.5s -> 23.0s...\n","\t0.6548\t = Validation score   (accuracy)\n","\t18.24s\t = Training   runtime\n","\t0.89s\t = Validation runtime\n","Fitting model: XGBoost_BAG_L1 ... Training model for up to 3.86s of the 150.37s of remaining time.\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=7.11%)\n","\t0.5995\t = Validation score   (accuracy)\n","\t3.42s\t = Training   runtime\n","\t0.38s\t = Validation runtime\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 143.70s of remaining time.\n","\tEnsemble Weights: {'LightGBM_BAG_L1': 1.0}\n","\t0.7674\t = Validation score   (accuracy)\n","\t0.8s\t = Training   runtime\n","\t0.01s\t = Validation runtime\n","Fitting 5 L2 models, fit_strategy=\"sequential\" ...\n","Fitting model: LightGBM_BAG_L2 ... Training model for up to 142.84s of the 142.81s of remaining time.\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=5.44%)\n","\t0.7767\t = Validation score   (accuracy)\n","\t21.6s\t = Training   runtime\n","\t1.28s\t = Validation runtime\n","Fitting model: LightGBM_2_BAG_L2 ... Training model for up to 118.13s of the 118.10s of remaining time.\n","\tWarning: Exception caused LightGBM_2_BAG_L2 to fail during training... Skipping this model.\n","\t\tSpecified num_gpus per model base is more than the total: 0\n","Detailed Traceback:\n","Traceback (most recent call last):\n","  File \"/opt/anaconda3/lib/python3.12/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2106, in _train_and_save\n","    model = self._train_single(**model_fit_kwargs)\n","            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/opt/anaconda3/lib/python3.12/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1993, in _train_single\n","    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n","            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/opt/anaconda3/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 914, in fit\n","    kwargs = self._preprocess_fit_args(**kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/opt/anaconda3/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 566, in _preprocess_fit_args\n","    kwargs = self._preprocess_fit_resources(**kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/opt/anaconda3/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 816, in _preprocess_fit_resources\n","    return self._calculate_total_resources(silent=silent, total_resources=total_resources, parallel_hpo=parallel_hpo, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/opt/anaconda3/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 697, in _calculate_total_resources\n","    user_specified_lower_level_num_gpus = self._process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble(\n","                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/opt/anaconda3/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 642, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n","    assert user_specified_model_level_resource <= system_resource, f\"Specified {resource_type} per model base is more than the total: {system_resource}\"\n","AssertionError: Specified num_gpus per model base is more than the total: 0\n","Fitting model: RandomForest_BAG_L2 ... Training model for up to 117.85s of the 117.82s of remaining time.\n","\t0.7751\t = Validation score   (accuracy)\n","\t43.49s\t = Training   runtime\n","\t2.11s\t = Validation runtime\n","Fitting model: XGBoost_BAG_L2 ... Training model for up to 71.92s of the 71.90s of remaining time.\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=8.93%)\n","\t0.7772\t = Validation score   (accuracy)\n","\t35.15s\t = Training   runtime\n","\t0.89s\t = Validation runtime\n","Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 34.31s of the 34.28s of remaining time.\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=4.26%)\n","\t0.7761\t = Validation score   (accuracy)\n","\t28.71s\t = Training   runtime\n","\t1.88s\t = Validation runtime\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 2.84s of remaining time.\n","\tEnsemble Weights: {'XGBoost_BAG_L2': 0.818, 'LightGBM_BAG_L2': 0.182}\n","\t0.7772\t = Validation score   (accuracy)\n","\t1.0s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","AutoGluon training complete, total runtime = 437.87s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 40.0 rows/s (8344 batch size)\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/biocorn/Documents/2025/SuperAI/Hackathon/5_Domain/Sleep Stage Classification/best_model\")\n"]},{"name":"stdout","output_type":"stream","text":["Finish!\n"]}],"source":["predictor = TabularPredictor(label='label',\n","                            problem_type='multiclass',\n","                            path=save_path,\n","                            ).fit(\n","                                df_train_,\n","                                presets='best_quality',\n","                                hyperparameters=hyperparameters,\n","                                time_limit=time_limit\n","                            )\n","print(\"Finish!\")"]},{"cell_type":"code","execution_count":null,"id":"8dadaa29-cd98-41f5-a3ee-32f8effb9cec","metadata":{"id":"8dadaa29-cd98-41f5-a3ee-32f8effb9cec","outputId":"b23df52f-7881-4c3e-bf55-4590218fc320"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>score_val</th>\n","      <th>eval_metric</th>\n","      <th>pred_time_val</th>\n","      <th>fit_time</th>\n","      <th>pred_time_val_marginal</th>\n","      <th>fit_time_marginal</th>\n","      <th>stack_level</th>\n","      <th>can_infer</th>\n","      <th>fit_order</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>WeightedEnsemble_L3</td>\n","      <td>0.777212</td>\n","      <td>accuracy</td>\n","      <td>209.609222</td>\n","      <td>317.301092</td>\n","      <td>0.003641</td>\n","      <td>1.000319</td>\n","      <td>3</td>\n","      <td>True</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>XGBoost_BAG_L2</td>\n","      <td>0.777152</td>\n","      <td>accuracy</td>\n","      <td>208.329748</td>\n","      <td>294.701894</td>\n","      <td>0.886821</td>\n","      <td>35.151566</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>LightGBM_BAG_L2</td>\n","      <td>0.776672</td>\n","      <td>accuracy</td>\n","      <td>208.718760</td>\n","      <td>281.149207</td>\n","      <td>1.275833</td>\n","      <td>21.598879</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NeuralNetTorch_BAG_L2</td>\n","      <td>0.776148</td>\n","      <td>accuracy</td>\n","      <td>209.327217</td>\n","      <td>288.262141</td>\n","      <td>1.884290</td>\n","      <td>28.711813</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>RandomForest_BAG_L2</td>\n","      <td>0.775144</td>\n","      <td>accuracy</td>\n","      <td>209.555920</td>\n","      <td>303.036646</td>\n","      <td>2.112993</td>\n","      <td>43.486319</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>LightGBM_BAG_L1</td>\n","      <td>0.767413</td>\n","      <td>accuracy</td>\n","      <td>206.170805</td>\n","      <td>237.893251</td>\n","      <td>206.170805</td>\n","      <td>237.893251</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>WeightedEnsemble_L2</td>\n","      <td>0.767413</td>\n","      <td>accuracy</td>\n","      <td>206.176936</td>\n","      <td>238.695412</td>\n","      <td>0.006131</td>\n","      <td>0.802161</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>RandomForest_BAG_L1</td>\n","      <td>0.654761</td>\n","      <td>accuracy</td>\n","      <td>0.894863</td>\n","      <td>18.237078</td>\n","      <td>0.894863</td>\n","      <td>18.237078</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>XGBoost_BAG_L1</td>\n","      <td>0.599536</td>\n","      <td>accuracy</td>\n","      <td>0.377259</td>\n","      <td>3.419998</td>\n","      <td>0.377259</td>\n","      <td>3.419998</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   model  score_val eval_metric  pred_time_val    fit_time  \\\n","0    WeightedEnsemble_L3   0.777212    accuracy     209.609222  317.301092   \n","1         XGBoost_BAG_L2   0.777152    accuracy     208.329748  294.701894   \n","2        LightGBM_BAG_L2   0.776672    accuracy     208.718760  281.149207   \n","3  NeuralNetTorch_BAG_L2   0.776148    accuracy     209.327217  288.262141   \n","4    RandomForest_BAG_L2   0.775144    accuracy     209.555920  303.036646   \n","5        LightGBM_BAG_L1   0.767413    accuracy     206.170805  237.893251   \n","6    WeightedEnsemble_L2   0.767413    accuracy     206.176936  238.695412   \n","7    RandomForest_BAG_L1   0.654761    accuracy       0.894863   18.237078   \n","8         XGBoost_BAG_L1   0.599536    accuracy       0.377259    3.419998   \n","\n","   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n","0                0.003641           1.000319            3       True   \n","1                0.886821          35.151566            2       True   \n","2                1.275833          21.598879            2       True   \n","3                1.884290          28.711813            2       True   \n","4                2.112993          43.486319            2       True   \n","5              206.170805         237.893251            1       True   \n","6                0.006131           0.802161            2       True   \n","7                0.894863          18.237078            1       True   \n","8                0.377259           3.419998            1       True   \n","\n","   fit_order  \n","0          9  \n","1          7  \n","2          5  \n","3          8  \n","4          6  \n","5          1  \n","6          4  \n","7          2  \n","8          3  "]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["predictor.leaderboard()"]},{"cell_type":"code","execution_count":null,"id":"1e02b5e8-2984-4574-bc09-a6fb141a3e26","metadata":{"id":"1e02b5e8-2984-4574-bc09-a6fb141a3e26"},"outputs":[],"source":["sample_submission = pd.read_csv(\"sample_submission.csv\")"]},{"cell_type":"code","execution_count":null,"id":"88d97228-39c0-4c0e-a197-c34061639cec","metadata":{"id":"88d97228-39c0-4c0e-a197-c34061639cec"},"outputs":[],"source":["y_pred = predictor.predict(df_test_)"]},{"cell_type":"code","execution_count":null,"id":"be7460a7-8104-4e16-95e1-6016ef4fbe30","metadata":{"id":"be7460a7-8104-4e16-95e1-6016ef4fbe30","outputId":"310685bd-32a5-492d-86e9-4fa9770bc10f"},"outputs":[{"data":{"text/plain":["labels\n","N2    5241\n","W     2273\n","N1     219\n","R       96\n","N3       3\n","Name: count, dtype: int64"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["sample_submission['labels'] = y_pred\n","sample_submission['labels'].value_counts()"]},{"cell_type":"code","execution_count":null,"id":"4f315c22-9cd5-40b2-8a94-250b79920ecf","metadata":{"id":"4f315c22-9cd5-40b2-8a94-250b79920ecf","outputId":"4dee2b0d-ff39-47d3-d4cd-09c83ad5d53c"},"outputs":[{"data":{"text/plain":["labels\n","N2    5241\n","W     2273\n","N1     219\n","R       96\n","N3       3\n","Name: count, dtype: int64"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["sample_submission.to_csv(\"submission_6.csv\", index=False)\n","sample_submission['labels'].value_counts()"]}],"metadata":{"kernelspec":{"display_name":"Python [conda env:base] *","language":"python","name":"conda-base-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}