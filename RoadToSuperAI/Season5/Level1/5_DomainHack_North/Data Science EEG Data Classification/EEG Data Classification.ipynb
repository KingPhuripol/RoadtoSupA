{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN3gWVj4pwnXGy1mRBLmKFa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q3XNEJr3-mi_","executionInfo":{"status":"ok","timestamp":1742006278554,"user_tz":-420,"elapsed":112,"user":{"displayName":"Purinut Polasa (Nano)","userId":"01246297602617636281"}},"outputId":"f5dee00f-06f9-40fa-e5ba-fc8082aecb2b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/eeg-data-classification.zip\n","  inflating: Sample_submission.csv   \n","  inflating: test.csv                \n","  inflating: train.csv               \n"]}],"source":["!unzip /content/eeg-data-classification.zip"]},{"cell_type":"code","source":["!pip -q install autogluon"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CNAod_sQ_q6u","executionInfo":{"status":"ok","timestamp":1742006524982,"user_tz":-420,"elapsed":233693,"user":{"displayName":"Purinut Polasa (Nano)","userId":"01246297602617636281"}},"outputId":"9a739c7c-624f-467d-d886-e89469866480"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.2/266.2 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/64.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m430.0/430.0 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.2/352.2 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.7/174.7 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.2/68.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.7/196.7 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.4/324.4 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.6/139.6 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m115.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.8/315.8 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.5/906.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.3/819.3 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m680.1/680.1 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.5.1 which is incompatible.\n","textblob 0.19.0 requires nltk>=3.9, but you have nltk 3.8.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from autogluon.tabular import TabularPredictor\n","import os\n","from sklearn.metrics import accuracy_score, classification_report"],"metadata":{"id":"hckANYDP_gzM","executionInfo":{"status":"ok","timestamp":1742006565295,"user_tz":-420,"elapsed":3187,"user":{"displayName":"Purinut Polasa (Nano)","userId":"01246297602617636281"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["train_path = 'train.csv'  # Update this path if your file is in a different location\n","test_path = 'test.csv'    # Update this path if your file is in a different location\n","submission_path = 'submission.csv'  # Output path for predictions"],"metadata":{"id":"Zd7KofQ8_1Se","executionInfo":{"status":"ok","timestamp":1742006565349,"user_tz":-420,"elapsed":46,"user":{"displayName":"Purinut Polasa (Nano)","userId":"01246297602617636281"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["train_data = pd.read_csv(train_path)\n","test_data = pd.read_csv(test_path)\n","\n","print(\"Training data shape:\", train_data.shape)\n","print(\"Test data shape:\", test_data.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UApOYIZsAfoh","executionInfo":{"status":"ok","timestamp":1742006565391,"user_tz":-420,"elapsed":47,"user":{"displayName":"Purinut Polasa (Nano)","userId":"01246297602617636281"}},"outputId":"84af2881-9594-4af3-c0f0-5b9f77bd99bd"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Training data shape: (7488, 18)\n","Test data shape: (7488, 18)\n"]}]},{"cell_type":"code","source":["print(\"Missing values in training data:\", train_data.isnull().sum().sum())\n","print(\"Missing values in test data:\", test_data.isnull().sum().sum())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4zxFzB6jAjI9","executionInfo":{"status":"ok","timestamp":1742006567587,"user_tz":-420,"elapsed":13,"user":{"displayName":"Purinut Polasa (Nano)","userId":"01246297602617636281"}},"outputId":"611249a0-4903-4b51-e55d-af5dad9a8bce"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Missing values in training data: 5570\n","Missing values in test data: 12923\n"]}]},{"cell_type":"code","source":["print(\"\\nTraining data statistics:\")\n","print(train_data.describe())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ALMMKbXpAk5W","executionInfo":{"status":"ok","timestamp":1742006568241,"user_tz":-420,"elapsed":58,"user":{"displayName":"Purinut Polasa (Nano)","userId":"01246297602617636281"}},"outputId":"c018c1e4-8c12-4972-9e0d-4167a63f6e79"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Training data statistics:\n","                id           V0           V1           V2           V3  \\\n","count  7488.000000  7488.000000  7488.000000  6974.000000  6224.000000   \n","mean   3743.500000     0.502847     0.338744     0.414566     0.353979   \n","std    2161.743741     0.289789     0.123015     0.118579     0.113369   \n","min       0.000000     0.000020     0.001666     0.002030     0.000000   \n","25%    1871.750000     0.253722     0.271370     0.338785     0.279900   \n","50%    3743.500000     0.506557     0.316577     0.399992     0.345080   \n","75%    5615.250000     0.754679     0.371844     0.467367     0.391288   \n","max    7487.000000     0.999774     0.989972     1.000000     0.994595   \n","\n","                V4           V5           V6           V7           V8  \\\n","count  7488.000000  5987.000000  7488.000000  7488.000000  7488.000000   \n","mean      0.334531     0.233684     0.283537     0.308027     0.295842   \n","std       0.109179     0.108096     0.098026     0.137870     0.111823   \n","min       0.000000     0.032207     0.000000     0.000000     0.003098   \n","25%       0.259385     0.170913     0.239241     0.208785     0.227447   \n","50%       0.323514     0.216079     0.271531     0.292955     0.283519   \n","75%       0.387696     0.267723     0.317241     0.377126     0.345787   \n","max       0.957195     0.980625     1.000000     1.000000     1.000000   \n","\n","                V9          V10          V11          V12          V13  \\\n","count  7232.000000  7488.000000  7488.000000  7488.000000  7488.000000   \n","mean      0.311592     0.498346     0.374194     0.440964     0.397466   \n","std       0.103822     0.290332     0.094519     0.105341     0.102383   \n","min       0.038709     0.000018     0.029322     0.000000     0.005180   \n","25%       0.247055     0.247642     0.322733     0.388533     0.338513   \n","50%       0.300621     0.494797     0.366740     0.432655     0.385385   \n","75%       0.357147     0.752038     0.413226     0.481210     0.440077   \n","max       0.997040     0.999967     1.000000     0.993371     0.984359   \n","\n","               V14          V15        Class  \n","count  5453.000000  7488.000000  7488.000000  \n","mean      0.417499     0.424139     0.448851  \n","std       0.085656     0.104564     0.497410  \n","min       0.010492     0.000000     0.000000  \n","25%       0.376641     0.370992     0.000000  \n","50%       0.410753     0.407245     0.000000  \n","75%       0.447501     0.456064     1.000000  \n","max       0.981626     0.980473     1.000000  \n"]}]},{"cell_type":"code","source":["X_train = train_data.drop('Class', axis=1)\n","y_train = train_data['Class']"],"metadata":{"id":"ISSiDnxbAnSv","executionInfo":{"status":"ok","timestamp":1742006570541,"user_tz":-420,"elapsed":14,"user":{"displayName":"Purinut Polasa (Nano)","userId":"01246297602617636281"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["save_path = 'agModels-eeg-eye'"],"metadata":{"id":"xv0tpjiSAqIT","executionInfo":{"status":"ok","timestamp":1742006571070,"user_tz":-420,"elapsed":8,"user":{"displayName":"Purinut Polasa (Nano)","userId":"01246297602617636281"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["predictor = TabularPredictor(\n","    label='Class',\n","    path=save_path,\n","    eval_metric='roc_auc',\n","    problem_type='binary'\n",")"],"metadata":{"id":"78WaeO6hAr_v","executionInfo":{"status":"ok","timestamp":1742006573185,"user_tz":-420,"elapsed":8,"user":{"displayName":"Purinut Polasa (Nano)","userId":"01246297602617636281"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["predictor.fit(\n","    train_data=train_data,\n","    time_limit=600,\n","    presets='best_quality',  # Use high quality preset for better performance\n","    verbosity=2  # Output detailed information during training\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1y9NJLPTAuW1","executionInfo":{"status":"ok","timestamp":1742007183433,"user_tz":-420,"elapsed":609577,"user":{"displayName":"Purinut Polasa (Nano)","userId":"01246297602617636281"}},"outputId":"95e951a6-ea72-437d-e60d-afaf38c6e8df"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["Verbosity: 2 (Standard Logging)\n","=================== System Info ===================\n","AutoGluon Version:  1.2\n","Python Version:     3.11.11\n","Operating System:   Linux\n","Platform Machine:   x86_64\n","Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n","CPU Count:          2\n","Memory Avail:       11.39 GB / 12.67 GB (89.9%)\n","Disk Space Avail:   190.50 GB / 235.68 GB (80.8%)\n","===================================================\n","Presets specified: ['best_quality']\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n","\tRunning DyStack for up to 150s of the 600s of remaining time (25%).\n","\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n","2025-03-15 02:42:58,342\tINFO worker.py:1810 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n","\t\tContext path: \"/content/agModels-eeg-eye/ds_sub_fit/sub_fit_ho\"\n","\u001b[36m(_dystack pid=2078)\u001b[0m Running DyStack sub-fit ...\n","\u001b[36m(_dystack pid=2078)\u001b[0m Beginning AutoGluon training ... Time limit = 145s\n","\u001b[36m(_dystack pid=2078)\u001b[0m AutoGluon will save models to \"/content/agModels-eeg-eye/ds_sub_fit/sub_fit_ho\"\n","\u001b[36m(_dystack pid=2078)\u001b[0m Train Data Rows:    6656\n","\u001b[36m(_dystack pid=2078)\u001b[0m Train Data Columns: 17\n","\u001b[36m(_dystack pid=2078)\u001b[0m Label Column:       Class\n","\u001b[36m(_dystack pid=2078)\u001b[0m Problem Type:       binary\n","\u001b[36m(_dystack pid=2078)\u001b[0m Preprocessing data ...\n","\u001b[36m(_dystack pid=2078)\u001b[0m Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n","\u001b[36m(_dystack pid=2078)\u001b[0m Using Feature Generators to preprocess the data ...\n","\u001b[36m(_dystack pid=2078)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n","\u001b[36m(_dystack pid=2078)\u001b[0m \tAvailable Memory:                    11174.86 MB\n","\u001b[36m(_dystack pid=2078)\u001b[0m \tTrain Data (Original)  Memory Usage: 0.86 MB (0.0% of available memory)\n","\u001b[36m(_dystack pid=2078)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n","\u001b[36m(_dystack pid=2078)\u001b[0m \tStage 1 Generators:\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n","\u001b[36m(_dystack pid=2078)\u001b[0m \tStage 2 Generators:\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n","\u001b[36m(_dystack pid=2078)\u001b[0m \tStage 3 Generators:\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n","\u001b[36m(_dystack pid=2078)\u001b[0m \tStage 4 Generators:\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n","\u001b[36m(_dystack pid=2078)\u001b[0m \tStage 5 Generators:\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n","\u001b[36m(_dystack pid=2078)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t\t('float', []) : 16 | ['V0', 'V1', 'V2', 'V3', 'V4', ...]\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t\t('int', [])   :  1 | ['id']\n","\u001b[36m(_dystack pid=2078)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t\t('float', []) : 16 | ['V0', 'V1', 'V2', 'V3', 'V4', ...]\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t\t('int', [])   :  1 | ['id']\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t0.0s = Fit runtime\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t17 features in original data used to generate 17 features in processed data.\n","\u001b[36m(_dystack pid=2078)\u001b[0m \tTrain Data (Processed) Memory Usage: 0.86 MB (0.0% of available memory)\n","\u001b[36m(_dystack pid=2078)\u001b[0m Data preprocessing and feature engineering runtime = 0.05s ...\n","\u001b[36m(_dystack pid=2078)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n","\u001b[36m(_dystack pid=2078)\u001b[0m \tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n","\u001b[36m(_dystack pid=2078)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n","\u001b[36m(_dystack pid=2078)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n","\u001b[36m(_dystack pid=2078)\u001b[0m User-specified model hyperparameters to be fit:\n","\u001b[36m(_dystack pid=2078)\u001b[0m {\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n","\u001b[36m(_dystack pid=2078)\u001b[0m }\n","\u001b[36m(_dystack pid=2078)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n","\u001b[36m(_dystack pid=2078)\u001b[0m Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n","\u001b[36m(_dystack pid=2078)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 96.68s of the 145.05s of remaining time.\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t0.5033\t = Validation score   (roc_auc)\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t0.01s\t = Training   runtime\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t0.22s\t = Validation runtime\n","\u001b[36m(_dystack pid=2078)\u001b[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 96.43s of the 144.79s of remaining time.\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t0.5081\t = Validation score   (roc_auc)\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t0.01s\t = Training   runtime\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t0.21s\t = Validation runtime\n","\u001b[36m(_dystack pid=2078)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 96.20s of the 144.56s of remaining time.\n","\u001b[36m(_dystack pid=2078)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.08%)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_ray_fit pid=2209)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.299077\n","\u001b[36m(_ray_fit pid=2345)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.300061\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n","\u001b[36m(_ray_fit pid=2483)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.310969\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2593)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.287974\u001b[32m [repeated 4x across cluster]\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_dystack pid=2078)\u001b[0m \t0.9519\t = Validation score   (roc_auc)\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t54.35s\t = Training   runtime\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t2.66s\t = Validation runtime\n","\u001b[36m(_dystack pid=2078)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 37.80s of the 86.16s of remaining time.\n","\u001b[36m(_dystack pid=2078)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.08%)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36m(_ray_fit pid=2730)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.23998\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2834)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.228639\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2946)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.24499\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=3063)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.238469\u001b[32m [repeated 2x across cluster]\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[36m(_dystack pid=2078)\u001b[0m \t0.9661\t = Validation score   (roc_auc)\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t41.25s\t = Training   runtime\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t0.91s\t = Validation runtime\n","\u001b[36m(_dystack pid=2078)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 145.05s of the 41.05s of remaining time.\n","\u001b[36m(_dystack pid=2078)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L1': 0.929, 'LightGBMXT_BAG_L1': 0.071}\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t0.9662\t = Validation score   (roc_auc)\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t0.14s\t = Training   runtime\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t0.0s\t = Validation runtime\n","\u001b[36m(_dystack pid=2078)\u001b[0m Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n","\u001b[36m(_dystack pid=2078)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 40.89s of the 40.87s of remaining time.\n","\u001b[36m(_dystack pid=2078)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.10%)\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t0.9645\t = Validation score   (roc_auc)\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t26.58s\t = Training   runtime\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t0.11s\t = Validation runtime\n","\u001b[36m(_dystack pid=2078)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 11.30s of the 11.28s of remaining time.\n","\u001b[36m(_dystack pid=2078)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.10%)\n","\u001b[36m(_ray_fit pid=3754)\u001b[0m \tRan out of time, early stopping on iteration 368. Best iteration is:\n","\u001b[36m(_ray_fit pid=3754)\u001b[0m \t[130]\tvalid_set's binary_logloss: 0.237869\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t0.9646\t = Validation score   (roc_auc)\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t28.38s\t = Training   runtime\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t0.11s\t = Validation runtime\n","\u001b[36m(_dystack pid=2078)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 145.05s of the -20.30s of remaining time.\n","\u001b[36m(_dystack pid=2078)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L1': 0.636, 'LightGBM_BAG_L2': 0.273, 'LightGBMXT_BAG_L2': 0.091}\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t0.9664\t = Validation score   (roc_auc)\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t0.36s\t = Training   runtime\n","\u001b[36m(_dystack pid=2078)\u001b[0m \t0.0s\t = Validation runtime\n","\u001b[36m(_dystack pid=2078)\u001b[0m AutoGluon training complete, total runtime = 165.79s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 216.4 rows/s (832 batch size)\n","\u001b[36m(_dystack pid=2078)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/agModels-eeg-eye/ds_sub_fit/sub_fit_ho\")\n","\u001b[36m(_dystack pid=2078)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n","Leaderboard on holdout data (DyStack):\n","                   model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n","0        LightGBM_BAG_L2       0.970889   0.964631     roc_auc        4.241449       4.106333  123.985313                 0.097933                0.114740          28.375375            2       True          7\n","1    WeightedEnsemble_L3       0.970568   0.966420     roc_auc        4.447757       4.223434  150.918532                 0.005594                0.003722           0.355018            3       True          8\n","2        LightGBM_BAG_L1       0.969306   0.966060     roc_auc        0.564490       0.908083   41.248216                 0.564490                0.908083          41.248216            1       True          4\n","3      LightGBMXT_BAG_L2       0.969289   0.964499     roc_auc        4.344230       4.104972  122.188139                 0.200714                0.113378          26.578202            2       True          6\n","4    WeightedEnsemble_L2       0.968891   0.966236     roc_auc        4.005089       3.565192   95.740796                 0.002306                0.001668           0.142690            2       True          5\n","5      LightGBMXT_BAG_L1       0.947847   0.951889     roc_auc        3.438294       2.655442   54.349890                 3.438294                2.655442          54.349890            1       True          3\n","6  KNeighborsUnif_BAG_L1       0.492877   0.503303     roc_auc        0.097536       0.221374    0.006152                 0.097536                0.221374           0.006152            1       True          1\n","7  KNeighborsDist_BAG_L1       0.492176   0.508096     roc_auc        0.043196       0.206695    0.005680                 0.043196                0.206695           0.005680            1       True          2\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n","\t177s\t = DyStack   runtime |\t423s\t = Remaining runtime\n","Starting main fit with num_stack_levels=1.\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n","Beginning AutoGluon training ... Time limit = 423s\n","AutoGluon will save models to \"/content/agModels-eeg-eye\"\n","Train Data Rows:    7488\n","Train Data Columns: 17\n","Label Column:       Class\n","Problem Type:       binary\n","Preprocessing data ...\n","Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n","Using Feature Generators to preprocess the data ...\n","Fitting AutoMLPipelineFeatureGenerator...\n","\tAvailable Memory:                    11035.34 MB\n","\tTrain Data (Original)  Memory Usage: 0.97 MB (0.0% of available memory)\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n","\tStage 1 Generators:\n","\t\tFitting AsTypeFeatureGenerator...\n","\tStage 2 Generators:\n","\t\tFitting FillNaFeatureGenerator...\n","\tStage 3 Generators:\n","\t\tFitting IdentityFeatureGenerator...\n","\tStage 4 Generators:\n","\t\tFitting DropUniqueFeatureGenerator...\n","\tStage 5 Generators:\n","\t\tFitting DropDuplicatesFeatureGenerator...\n","\tTypes of features in original data (raw dtype, special dtypes):\n","\t\t('float', []) : 16 | ['V0', 'V1', 'V2', 'V3', 'V4', ...]\n","\t\t('int', [])   :  1 | ['id']\n","\tTypes of features in processed data (raw dtype, special dtypes):\n","\t\t('float', []) : 16 | ['V0', 'V1', 'V2', 'V3', 'V4', ...]\n","\t\t('int', [])   :  1 | ['id']\n","\t0.1s = Fit runtime\n","\t17 features in original data used to generate 17 features in processed data.\n","\tTrain Data (Processed) Memory Usage: 0.97 MB (0.0% of available memory)\n","Data preprocessing and feature engineering runtime = 0.09s ...\n","AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n","\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n","\tTo change this, specify the eval_metric parameter of Predictor()\n","Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n","User-specified model hyperparameters to be fit:\n","{\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n","\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n","}\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\n","Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n","Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 281.73s of the 422.69s of remaining time.\n","\t0.5024\t = Validation score   (roc_auc)\n","\t0.02s\t = Training   runtime\n","\t0.99s\t = Validation runtime\n","Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 280.68s of the 421.63s of remaining time.\n","\t0.506\t = Validation score   (roc_auc)\n","\t0.01s\t = Training   runtime\n","\t0.86s\t = Validation runtime\n","Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 279.77s of the 420.72s of remaining time.\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.09%)\n","\t0.9539\t = Validation score   (roc_auc)\n","\t56.31s\t = Training   runtime\n","\t3.25s\t = Validation runtime\n","Fitting model: LightGBM_BAG_L1 ... Training model for up to 219.27s of the 360.23s of remaining time.\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.08%)\n","\t0.9691\t = Validation score   (roc_auc)\n","\t44.87s\t = Training   runtime\n","\t1.29s\t = Validation runtime\n","Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 170.87s of the 311.82s of remaining time.\n","\t0.9534\t = Validation score   (roc_auc)\n","\t7.54s\t = Training   runtime\n","\t0.29s\t = Validation runtime\n","Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 162.93s of the 303.88s of remaining time.\n","\t0.9566\t = Validation score   (roc_auc)\n","\t6.27s\t = Training   runtime\n","\t0.29s\t = Validation runtime\n","Fitting model: CatBoost_BAG_L1 ... Training model for up to 156.28s of the 297.23s of remaining time.\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.11%)\n","\t0.9692\t = Validation score   (roc_auc)\n","\t135.31s\t = Training   runtime\n","\t0.12s\t = Validation runtime\n","Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 16.91s of the 157.87s of remaining time.\n","\t0.9428\t = Validation score   (roc_auc)\n","\t3.47s\t = Training   runtime\n","\t0.62s\t = Validation runtime\n","Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 12.57s of the 153.52s of remaining time.\n","\t0.9459\t = Validation score   (roc_auc)\n","\t1.93s\t = Training   runtime\n","\t0.32s\t = Validation runtime\n","Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 10.05s of the 151.01s of remaining time.\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.10%)\n","\t0.856\t = Validation score   (roc_auc)\n","\t39.7s\t = Training   runtime\n","\t0.38s\t = Validation runtime\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 108.47s of remaining time.\n","\tEnsemble Weights: {'CatBoost_BAG_L1': 0.48, 'LightGBM_BAG_L1': 0.4, 'RandomForestEntr_BAG_L1': 0.08, 'ExtraTreesEntr_BAG_L1': 0.04}\n","\t0.9722\t = Validation score   (roc_auc)\n","\t0.41s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n","Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 108.04s of the 108.00s of remaining time.\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.12%)\n","\t0.9737\t = Validation score   (roc_auc)\n","\t29.11s\t = Training   runtime\n","\t0.17s\t = Validation runtime\n","Fitting model: LightGBM_BAG_L2 ... Training model for up to 75.47s of the 75.44s of remaining time.\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.12%)\n","\t0.9733\t = Validation score   (roc_auc)\n","\t31.07s\t = Training   runtime\n","\t0.09s\t = Validation runtime\n","Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 39.10s of the 39.06s of remaining time.\n","\t0.9722\t = Validation score   (roc_auc)\n","\t5.67s\t = Training   runtime\n","\t0.4s\t = Validation runtime\n","Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 32.93s of the 32.90s of remaining time.\n","\t0.9731\t = Validation score   (roc_auc)\n","\t7.76s\t = Training   runtime\n","\t0.25s\t = Validation runtime\n","Fitting model: CatBoost_BAG_L2 ... Training model for up to 24.84s of the 24.80s of remaining time.\n","\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.16%)\n","\t0.9738\t = Validation score   (roc_auc)\n","\t30.6s\t = Training   runtime\n","\t0.11s\t = Validation runtime\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -8.69s of remaining time.\n","\tEnsemble Weights: {'CatBoost_BAG_L2': 0.4, 'LightGBM_BAG_L2': 0.267, 'LightGBMXT_BAG_L2': 0.2, 'RandomForestGini_BAG_L2': 0.067, 'RandomForestEntr_BAG_L2': 0.067}\n","\t0.9744\t = Validation score   (roc_auc)\n","\t0.52s\t = Training   runtime\n","\t0.0s\t = Validation runtime\n","AutoGluon training complete, total runtime = 432.07s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 158.4 rows/s (936 batch size)\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/agModels-eeg-eye\")\n"]},{"output_type":"execute_result","data":{"text/plain":["<autogluon.tabular.predictor.predictor.TabularPredictor at 0x7b729b2772d0>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["print(\"\\nModel Leaderboard:\")\n","leaderboard = predictor.leaderboard()\n","print(leaderboard)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nENlVJlxA05o","executionInfo":{"status":"ok","timestamp":1742007183451,"user_tz":-420,"elapsed":16,"user":{"displayName":"Purinut Polasa (Nano)","userId":"01246297602617636281"}},"outputId":"38acf542-357d-4727-ddf4-d61438c21bde"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Model Leaderboard:\n","                      model  score_val eval_metric  pred_time_val    fit_time  \\\n","0       WeightedEnsemble_L3   0.974404     roc_auc       9.438795  400.178091   \n","1           CatBoost_BAG_L2   0.973811     roc_auc       8.516526  326.037555   \n","2         LightGBMXT_BAG_L2   0.973742     roc_auc       8.573931  324.544181   \n","3           LightGBM_BAG_L2   0.973332     roc_auc       8.497792  326.506348   \n","4   RandomForestEntr_BAG_L2   0.973111     roc_auc       8.656322  303.193668   \n","5   RandomForestGini_BAG_L2   0.972213     roc_auc       8.803559  301.103309   \n","6       WeightedEnsemble_L2   0.972190     roc_auc       2.020361  188.789392   \n","7           CatBoost_BAG_L1   0.969187     roc_auc       0.118939  135.312459   \n","8           LightGBM_BAG_L1   0.969106     roc_auc       1.285079   44.871536   \n","9   RandomForestEntr_BAG_L1   0.956620     roc_auc       0.290321    6.266278   \n","10        LightGBMXT_BAG_L1   0.953852     roc_auc       3.245015   56.314628   \n","11  RandomForestGini_BAG_L1   0.953381     roc_auc       0.287147    7.542804   \n","12    ExtraTreesEntr_BAG_L1   0.945877     roc_auc       0.323797    1.930615   \n","13    ExtraTreesGini_BAG_L1   0.942782     roc_auc       0.621833    3.470226   \n","14   NeuralNetFastAI_BAG_L1   0.856028     roc_auc       0.376929   39.698012   \n","15    KNeighborsDist_BAG_L1   0.505953     roc_auc       0.858763    0.010870   \n","16    KNeighborsUnif_BAG_L1   0.502416     roc_auc       0.994975    0.015263   \n","\n","    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n","0                 0.001858           0.523795            3       True   \n","1                 0.113728          30.604864            2       True   \n","2                 0.171133          29.111489            2       True   \n","3                 0.094993          31.073657            2       True   \n","4                 0.253524           7.760977            2       True   \n","5                 0.400761           5.670618            2       True   \n","6                 0.002225           0.408503            2       True   \n","7                 0.118939         135.312459            1       True   \n","8                 1.285079          44.871536            1       True   \n","9                 0.290321           6.266278            1       True   \n","10                3.245015          56.314628            1       True   \n","11                0.287147           7.542804            1       True   \n","12                0.323797           1.930615            1       True   \n","13                0.621833           3.470226            1       True   \n","14                0.376929          39.698012            1       True   \n","15                0.858763           0.010870            1       True   \n","16                0.994975           0.015263            1       True   \n","\n","    fit_order  \n","0          17  \n","1          16  \n","2          12  \n","3          13  \n","4          15  \n","5          14  \n","6          11  \n","7           7  \n","8           4  \n","9           6  \n","10          3  \n","11          5  \n","12          9  \n","13          8  \n","14         10  \n","15          2  \n","16          1  \n"]}]},{"cell_type":"code","source":["if hasattr(predictor, 'feature_importance'):\n","    print(\"\\nFeature Importance:\")\n","    importance = predictor.feature_importance(data=train_data)\n","    print(importance)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"4STumPdqA3Mw","executionInfo":{"status":"error","timestamp":1742007975549,"user_tz":-420,"elapsed":792097,"user":{"displayName":"Purinut Polasa (Nano)","userId":"01246297602617636281"}},"outputId":"474a7630-a59b-4520-b6c4-cd9701290e26"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["Computing feature importance via permutation shuffling for 17 features using 5000 rows with 5 shuffle sets...\n"]},{"output_type":"stream","name":"stdout","text":["\n","Feature Importance:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","\t1669.04s\t= Expected runtime (333.81s per shuffle set)\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-3da6b2475ca0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'feature_importance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nFeature Importance:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mimportance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogluon/tabular/predictor/predictor.py\u001b[0m in \u001b[0;36mfeature_importance\u001b[0;34m(self, data, model, features, feature_stage, subsample_size, time_limit, num_shuffle_sets, include_confidence_band, confidence_level, silent)\u001b[0m\n\u001b[1;32m   3415\u001b[0m             \u001b[0mnum_shuffle_sets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtime_limit\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3417\u001b[0;31m         fi_df = self._learner.get_feature_importance(\n\u001b[0m\u001b[1;32m   3418\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3419\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogluon/tabular/learner/abstract_learner.py\u001b[0m in \u001b[0;36mget_feature_importance\u001b[0;34m(self, model, X, y, features, feature_stage, subsample_size, silent, **kwargs)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfeature_stage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"original\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m                 return trainer._get_feature_importance_raw(\n\u001b[0m\u001b[1;32m   1008\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubsample_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_get_feature_importance_raw\u001b[0;34m(self, X, y, model, eval_metric, **kwargs)\u001b[0m\n\u001b[1;32m   3445\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAbstractModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m         \u001b[0mpredict_func_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3447\u001b[0;31m         return compute_permutation_feature_importance(\n\u001b[0m\u001b[1;32m   3448\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3449\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogluon/core/utils/utils.py\u001b[0m in \u001b[0;36mcompute_permutation_feature_importance\u001b[0;34m(X, y, predict_func, eval_metric, features, subsample_size, num_shuffle_sets, predict_func_kwargs, transform_func, transform_func_kwargs, time_limit, silent, log_prefix, importance_as_list, random_state, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                 \u001b[0mX_raw_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_raw\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtransform_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtransform_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtransform_func_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_raw_transformed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_func_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m             \u001b[0mrow_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, model)\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_proba_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_predict_proba_model\u001b[0;34m(self, X, model, model_pred_proba_dict)\u001b[0m\n\u001b[1;32m   3260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3261\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict_proba_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_pred_proba_dict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3262\u001b[0;31m         \u001b[0mmodel_pred_proba_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_pred_proba_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_pred_proba_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_pred_proba_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3263\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3264\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36mget_model_pred_proba_dict\u001b[0;34m(self, X, models, model_pred_proba_dict, model_pred_time_dict, record_pred_time, use_val_cache)\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStackerEnsembleModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0mpreprocess_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_pred_proba_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_pred_proba_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m                 \u001b[0mmodel_pred_proba_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mmodel_pred_proba_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, normalize, record_time, **kwargs)\u001b[0m\n\u001b[1;32m   1045\u001b[0m         \u001b[0mtime_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrecord_time\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_proba_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams_aux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"temperature_scalar\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\u001b[0m in \u001b[0;36m_predict_proba_internal\u001b[0;34m(self, X, normalize, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0my_pred_proba\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_nonadaptive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m         \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred_proba\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_children\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my_pred_proba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, normalize, record_time, **kwargs)\u001b[0m\n\u001b[1;32m   1045\u001b[0m         \u001b[0mtime_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrecord_time\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_proba_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams_aux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"temperature_scalar\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogluon/core/models/abstract/abstract_model.py\u001b[0m in \u001b[0;36m_predict_proba_internal\u001b[0;34m(self, X, normalize, **kwargs)\u001b[0m\n\u001b[1;32m   1059\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnormalize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0mnormalize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_pred_probas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m         \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_pred_probas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogluon/tabular/models/lgb/lgb_model.py\u001b[0m in \u001b[0;36m_predict_proba\u001b[0;34m(self, X, num_cpus, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_cpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mQUANTILE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;31m# y_pred_proba is a pd.DataFrame, need to convert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features, **kwargs)\u001b[0m\n\u001b[1;32m   4746\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4747\u001b[0m                 \u001b[0mnum_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4748\u001b[0;31m         return predictor.predict(\n\u001b[0m\u001b[1;32m   4749\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4750\u001b[0m             \u001b[0mstart_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_iteration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features)\u001b[0m\n\u001b[1;32m   1183\u001b[0m             )\n\u001b[1;32m   1184\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             preds, nrow = self.__pred_for_np2d(\n\u001b[0m\u001b[1;32m   1186\u001b[0m                 \u001b[0mmat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m                 \u001b[0mstart_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_iteration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__pred_for_np2d\u001b[0;34m(self, mat, start_iteration, num_iteration, predict_type)\u001b[0m\n\u001b[1;32m   1342\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m             return self.__inner_predict_np2d(\n\u001b[0m\u001b[1;32m   1345\u001b[0m                 \u001b[0mmat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m                 \u001b[0mstart_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_iteration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__inner_predict_np2d\u001b[0;34m(self, mat, start_iteration, num_iteration, predict_type, preds)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0mout_num_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m         _safe_call(\n\u001b[0;32m-> 1291\u001b[0;31m             _LIB.LGBM_BoosterPredictForMat(\n\u001b[0m\u001b[1;32m   1292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m                 \u001b[0mptr_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["y_pred = predictor.predict(test_data)\n","print(\"\\nPrediction distribution:\")\n","print(y_pred.value_counts())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eA5ps5P7A5ou","executionInfo":{"status":"ok","timestamp":1742008000224,"user_tz":-420,"elapsed":21952,"user":{"displayName":"Purinut Polasa (Nano)","userId":"01246297602617636281"}},"outputId":"bde0a750-8c6c-4001-e38f-da08b531cee2"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n","/usr/local/lib/python3.11/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n","If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n","  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n"]},{"output_type":"stream","name":"stdout","text":["\n","Prediction distribution:\n","Class\n","0    4252\n","1    3236\n","Name: count, dtype: int64\n"]}]},{"cell_type":"code","source":["submission = pd.DataFrame()\n","submission['id'] = range(len(test_data))\n","submission['Class'] = y_pred\n","submission.to_csv(submission_path, index=False)\n","print(f\"\\nSubmission file saved to {submission_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Xwou0FEA-iH","executionInfo":{"status":"ok","timestamp":1742008000251,"user_tz":-420,"elapsed":26,"user":{"displayName":"Purinut Polasa (Nano)","userId":"01246297602617636281"}},"outputId":"03f8c20c-5825-4435-b317-db624e8e762e"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Submission file saved to submission.csv\n"]}]}]}